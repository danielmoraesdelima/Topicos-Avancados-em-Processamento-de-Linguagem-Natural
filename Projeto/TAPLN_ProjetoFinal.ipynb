{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TAPLN_ProjetoFinal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3c9d439dfc5a40f89745512a4e3596d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2d0f35306f4548e798030f199ba8f841",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fee3392254e447beb9576d5bf49a2436",
              "IPY_MODEL_70e61c5c4b0048e2844f9621dfbe42a2",
              "IPY_MODEL_df83d284277543f88177be135447ab34"
            ]
          }
        },
        "2d0f35306f4548e798030f199ba8f841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fee3392254e447beb9576d5bf49a2436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08518fb84956453ea85bdf2a99c7bdd4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0bddaf77964f4ff1a47bce32a6572c17"
          }
        },
        "70e61c5c4b0048e2844f9621dfbe42a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_be403b74d1224939bd122170e8218e9a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e31f463a2234150b24eaa176b6c032b"
          }
        },
        "df83d284277543f88177be135447ab34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bda1211407214be0a04f20b6a42acac6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 665kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95f7e78672ce45d79fe8970f3c770759"
          }
        },
        "08518fb84956453ea85bdf2a99c7bdd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0bddaf77964f4ff1a47bce32a6572c17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be403b74d1224939bd122170e8218e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e31f463a2234150b24eaa176b6c032b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bda1211407214be0a04f20b6a42acac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95f7e78672ce45d79fe8970f3c770759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84ab7d5a03324694914d4cfc8b3701db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d5fa7eda8dd14c79bd078f92fa4f8000",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5fd249c4050640b1b711c6d89085a446",
              "IPY_MODEL_82be925a745f4f2baa8fbe9daac136c4",
              "IPY_MODEL_a741fd8ab21646a1ad2fd6a5dacc838f"
            ]
          }
        },
        "d5fa7eda8dd14c79bd078f92fa4f8000": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5fd249c4050640b1b711c6d89085a446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_69b730509a7e407f8f2b8f4dac84335e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6cf9520f9f444ed8bbea0c22eb4256d4"
          }
        },
        "82be925a745f4f2baa8fbe9daac136c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9c7a7eb5340e4665bccd2f5344181f53",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_166efb7f0b2c46b9951cafe91ae83863"
          }
        },
        "a741fd8ab21646a1ad2fd6a5dacc838f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9cb612c45e42473092cc36d713f12e91",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 876B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4225fcbd224a499aba986280b6c43fb9"
          }
        },
        "69b730509a7e407f8f2b8f4dac84335e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6cf9520f9f444ed8bbea0c22eb4256d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c7a7eb5340e4665bccd2f5344181f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "166efb7f0b2c46b9951cafe91ae83863": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cb612c45e42473092cc36d713f12e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4225fcbd224a499aba986280b6c43fb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ade45b8399a4c528d82bb3748f1a082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a69f1a63ca6247c2971c4c14e0df6463",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_170937f75ddb4672acd9b6c3aaabde83",
              "IPY_MODEL_31556aabcb744c7ca2ce1de023d459a1",
              "IPY_MODEL_c5b17df296584663aa3db89504f7df74"
            ]
          }
        },
        "a69f1a63ca6247c2971c4c14e0df6463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "170937f75ddb4672acd9b6c3aaabde83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f57da676e1774a688cfe66f27f6f3d79",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9642e92e145645dc8f1a53870b361323"
          }
        },
        "31556aabcb744c7ca2ce1de023d459a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_24be63a16a6e46358cb325c363d5cd48",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55a8972fed1c4e7bac7c0570d668ced5"
          }
        },
        "c5b17df296584663aa3db89504f7df74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a0e482e9168c4e83a8680c67dddf2ccc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 891kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_574da8901d87410b8afd95e530721098"
          }
        },
        "f57da676e1774a688cfe66f27f6f3d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9642e92e145645dc8f1a53870b361323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24be63a16a6e46358cb325c363d5cd48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55a8972fed1c4e7bac7c0570d668ced5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0e482e9168c4e83a8680c67dddf2ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "574da8901d87410b8afd95e530721098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c01ec1eaee7b4f7b82f57af00d7757f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f6139022f46741a59fb8efcf68fdfa3f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0032a1ae05fc48cabe434047a55798b1",
              "IPY_MODEL_3bc5c86650b84f16b0610bd874b2e92e",
              "IPY_MODEL_f7ae70302d96465cbac0fb232f5c2739"
            ]
          }
        },
        "f6139022f46741a59fb8efcf68fdfa3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0032a1ae05fc48cabe434047a55798b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e7b4ab5fc5c44f7fbc7c18c275f8b537",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddf6ab9da7e542e7ae9aa90380451897"
          }
        },
        "3bc5c86650b84f16b0610bd874b2e92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_70c22dfca1744250854b2549a340805b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a106f7c51bb445d6936710ee859276f8"
          }
        },
        "f7ae70302d96465cbac0fb232f5c2739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_701c5c8de12943a7ae2ef0f503b4426d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 16.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed7a9cb9eabc4eda9be8530e134648ce"
          }
        },
        "e7b4ab5fc5c44f7fbc7c18c275f8b537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddf6ab9da7e542e7ae9aa90380451897": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70c22dfca1744250854b2549a340805b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a106f7c51bb445d6936710ee859276f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "701c5c8de12943a7ae2ef0f503b4426d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed7a9cb9eabc4eda9be8530e134648ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1aa1a61ecd540358d1d3564fdf60a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cbd4b859e77b4ac5b6e4c9243fbf04ed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6ac83391ad1840e0816adaf14dedafd3",
              "IPY_MODEL_fa352c717e8342328520e0cca0823914",
              "IPY_MODEL_c09f43e6e8584102b35bb06d11a87ebf"
            ]
          }
        },
        "cbd4b859e77b4ac5b6e4c9243fbf04ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ac83391ad1840e0816adaf14dedafd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ac1f3b3822234b6d985c144dcface8f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f793c743e7f4df5b93e472646e89305"
          }
        },
        "fa352c717e8342328520e0cca0823914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_004d9c79f722475b8364995ca6bd8b07",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9599a835324e4c82a0b8633fcf944673"
          }
        },
        "c09f43e6e8584102b35bb06d11a87ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e5cddac230be4070933f8a41544bd795",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 420M/420M [00:11&lt;00:00, 37.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e9fbd0eea30342b9a2955ac70b42778f"
          }
        },
        "ac1f3b3822234b6d985c144dcface8f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f793c743e7f4df5b93e472646e89305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "004d9c79f722475b8364995ca6bd8b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9599a835324e4c82a0b8633fcf944673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5cddac230be4070933f8a41544bd795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e9fbd0eea30342b9a2955ac70b42778f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC8QtjIAGtEE"
      },
      "source": [
        "#### TRABALHO FINAL DA DISCIPLINA − TÓPICOS AVANÇADOS EM PLN - 2021.2\n",
        "\n",
        "Aluno: Daniel Moraes\n",
        "\n",
        "Objetivos: Desenvolver o módulo de NLU (Natural Language Understanding) de um sistema para chatbot fim-a-fim que recebe dois textos em linguagem natural e define se o 2o texto é resposta para o 1o.texto.\n",
        "\n",
        "Será fornecido um dataset com 180000 pares de sentenças que representam diálogos positivos, em inglês. Os diálogos negativos deverão ser “montados” pela equipe.\n",
        "\n",
        "As equipes serão avaliadas pelos entregáveis e pelos resultados a partir de um conjunto de teste (dados não vistos – Held-Out Data) com 18000 pares de sentenças.\n",
        "\n",
        "#### Produtos Entregáveis:\n",
        "\n",
        "18/10/2021\n",
        "\n",
        "- Pré-processamento, Lematização e POS Tagger, NER, etc.\n",
        "- Estatística Descritiva do vocabulário constante no dataset, considerando os modelos de linguagem unigrama, bigrama, trigrama; analise da lei de potencia ou Lei de Zipf.\n",
        "- Vetorização das Sentenças (features)\n",
        "\n",
        "06/12/2021\n",
        "\n",
        "- Model Fitted e Resultados do processo de treinamento\n",
        "- Execução com Held-Out-Data (Dados não vistos)\n",
        "- Artigo resumo com 4 paginas\n",
        "- Apresentação Oral e Entrega do artigo: 06/12/2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPcAP3uCGtEL"
      },
      "source": [
        "#### IMPORTACAO E INSTALAÇÃO DE BIBLIOTECAS, GPUS ETC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyGv46UNyNYJ",
        "outputId": "bcda273b-bb6b-4234-f845-6f5c89b4c1ae"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Nov 20 12:05:36 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB1DfEpMgxpv",
        "outputId": "0a01ca63-8fc1-45c3-a1fd-06971aed795a"
      },
      "source": [
        "pip install --upgrade jupyter_http_over_ws>=0.0.7 && \\\n",
        "  jupyter serverextension enable --py jupyter_http_over_ws"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/jupyter-serverextension\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/jupyter_core/application.py\", line 267, in launch_instance\n",
            "    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/notebook/serverextensions.py\", line 293, in start\n",
            "    super(ServerExtensionApp, self).start()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/jupyter_core/application.py\", line 256, in start\n",
            "    self.subapp.start()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/notebook/serverextensions.py\", line 210, in start\n",
            "    self.toggle_server_extension_python(arg)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/notebook/serverextensions.py\", line 199, in toggle_server_extension_python\n",
            "    m, server_exts = _get_server_extension_metadata(package)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/notebook/serverextensions.py\", line 327, in _get_server_extension_metadata\n",
            "    m = import_item(module)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/traitlets/utils/importstring.py\", line 42, in import_item\n",
            "    return __import__(parts[0])\n",
            "ImportError: No module named jupyter_http_over_ws\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ban5ByDwyg-m",
        "outputId": "46792fd1-9b14-41b7-e45d-f238d09afd2e"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0ja-hVwUSv_"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "import string\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates \n",
        "from functools import partial"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgs8l4B9IaFO"
      },
      "source": [
        "#Pacotes NLTK\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "nltk.download('maxent_ne_chunker', quiet=True)\n",
        "nltk.download('words', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('rslp', quiet=True)\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords as sw\n",
        "from contextlib import redirect_stdout\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import RSLPStemmer\n",
        "from nltk.tokenize import RegexpTokenizer \n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from nltk.tokenize import TweetTokenizer \n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.stem import RSLPStemmer\n",
        "from nltk.text import TextCollection\n",
        "from collections import defaultdict\n",
        "import os\n",
        "from pprint import pprint\n",
        "import joblib\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "\n",
        "#Download das stopwords\n",
        "with redirect_stdout(open(os.devnull, \"w\")):\n",
        "    nltk.download(\"stopwords\", quiet=True) \n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download(\"all\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDiWE97GUqCi",
        "outputId": "ed67b206-c10d-4bdb-af12-b5882d2f149f"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece\n",
        "!python3 -m spacy download en\n",
        "!pip install transformers\n",
        "!pip install tensorflow==2.2.0-rc3\n",
        "!pip install torchvision "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████                        | 10 kB 25.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 25.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40 kB 16.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 41 kB 164 kB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.62.3)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30534 sha256=97140248e9821e937bde5cee41e91d3bbbf079c53f4605b314cb2fe4337e3f79\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/b6/e5/8c76ec779f54bc5c2f1b57d2200bb9c77616da83873e8acb53\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19473 sha256=c224fefcf805678f35596ebd4a25c97197f2ccc784a24c2d5327b68b97bc2c6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/fc/d2/a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7912 sha256=925891fa16fd6386327ec5d84c25d05f0c8744ea8158da9ab2b842a0b1c7a4d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/11/67/33cc51bbee127cb8fb2ba549cd29109b2f22da43ddf9969716\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 7.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 41.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 55.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n",
            "Collecting tensorflow==2.2.0-rc3\n",
            "  Downloading tensorflow-2.2.0rc3-cp37-cp37m-manylinux2010_x86_64.whl (516.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2 MB 10 kB/s \n",
            "\u001b[?25hCollecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting tensorboard<2.3.0,>=2.2.0\n",
            "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 32.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (1.4.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (1.42.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (1.13.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (1.1.0)\n",
            "Collecting h5py<2.11.0,>=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 54.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.3.0,>=2.2.0rc0\n",
            "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
            "\u001b[K     |████████████████████████████████| 454 kB 64.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (0.37.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (0.12.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (3.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (3.1.1)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, h5py, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "Successfully installed gast-0.3.3 h5py-2.10.0 tensorboard-2.2.2 tensorflow-2.2.0rc3 tensorflow-estimator-2.2.0\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.10.0+cu111)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bWr4zpMnUuTM",
        "outputId": "56087bb3-2bfd-4922-8fc0-ecadceb89d6d"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import bert\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0-rc3'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18u8ektgEIMh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "96ce2a18-0db9-4050-a22e-df22a72faa45"
      },
      "source": [
        "!pip install tensorflow==2.4.1\n",
        "#!pip install keras==2.4.3\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.4.1\n",
            "  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3 MB 13 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
            "Collecting tensorboard~=2.4\n",
            "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 47.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.37.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.3.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.12.0)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 47.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.10.0)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 39.7 MB/s \n",
            "\u001b[?25hCollecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.1)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68719 sha256=d380bd0ca0a5486ce192a0ce8daf99f16284b339b8cb43c7b8d97e205d9e85eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, grpcio, wrapt, tensorflow-estimator, tensorboard, flatbuffers, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.42.0\n",
            "    Uninstalling grpcio-1.42.0:\n",
            "      Successfully uninstalled grpcio-1.42.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.13.3\n",
            "    Uninstalling wrapt-1.13.3:\n",
            "      Successfully uninstalled wrapt-1.13.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.2.0rc3\n",
            "    Uninstalling tensorflow-2.2.0rc3:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc3\n",
            "Successfully installed flatbuffers-1.12 grpcio-1.32.0 tensorboard-2.7.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator",
                  "typing_extensions",
                  "wrapt"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0-rc3'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebVbWPuz8iLa",
        "outputId": "afbff49e-0de4-494f-fc6e-da54c5f93130"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44U-7_y3GtEV"
      },
      "source": [
        "#### Produtos Entregáveis:\n",
        "\n",
        "18/10/2021\n",
        "\n",
        "- Pré-processamento, Lematização e POS Tagger, NER, etc.\n",
        "- Estatística Descritiva do vocabulário constante no dataset, considerando os modelos de linguagem unigrama, bigrama, trigrama; analise da lei de potencia ou Lei de Zipf.\n",
        "- Vetorização das Sentenças (features)\n",
        "\n",
        "#### Tratamento inicial do texto\n",
        "\n",
        "Converte o texto de cada sentença, separadamente, em minúsculo e remove espaços e tabulações extras. O resultado é guardado no DataFrame referente a cada sentenca em uma nova coluna.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC2V2ql5Jm_T",
        "outputId": "8fd98a19-3095-40ac-b9ee-cb0cb123f5fc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccim8p3sIgoD"
      },
      "source": [
        "path = r\"/content/drive/MyDrive/Colab Notebooks/TopicosPLN/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OPippHvPUuT8",
        "outputId": "bd6fbb3a-ddf9-4189-94f3-8949d70260b9"
      },
      "source": [
        "#Importando o Dataset\n",
        "#df = pd.read_csv(path+'ChatBotDataset.xlsx', delimiter=';', encoding= 'mac_roman')\n",
        "df = pd.read_excel(path+'ChatBotDataset.xlsx')\n",
        "\n",
        "#conversão da coluna 'pair_ID' de inteiro para string\n",
        "df['pair_ID'] = df['pair_ID'].astype('str')\n",
        "\n",
        "#Visualização do Cabeçalho dos dados\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pair_ID</th>\n",
              "      <th>message</th>\n",
              "      <th>response</th>\n",
              "      <th>entailment_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>b'have you heard of the upcoming black panther...</td>\n",
              "      <td>b'i have and i am so in love with the trailer ...</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>b'it looks remarkable so far!\\r\\n'</td>\n",
              "      <td>b'chadwick really is a good actor for black pa...</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>b'i agree!. he really is suitable for the role...</td>\n",
              "      <td>b'the trailer was kind of sad though.\\r\\n'</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b'how so? did it bother you when his father di...</td>\n",
              "      <td>b'yes, it did, but i hope he become one of the...</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>b'i second that statement!\\r\\n'</td>\n",
              "      <td>b'but the movie will be a while until it is re...</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  pair_ID  ... entailment_label\n",
              "0       0  ...         POSITIVE\n",
              "1       1  ...         POSITIVE\n",
              "2       2  ...         POSITIVE\n",
              "3       3  ...         POSITIVE\n",
              "4       4  ...         POSITIVE\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oul1956NSu9_",
        "outputId": "081763ac-8cc8-4a1b-92da-07806a10471c"
      },
      "source": [
        "df.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pair_ID             320002\n",
              "message             320002\n",
              "response            320002\n",
              "entailment_label    320002\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FllNQws6H3ZK",
        "outputId": "02724934-89d7-4328-c0b7-cce1a87bf5e3"
      },
      "source": [
        "#Função para tratar o texto\n",
        "def tratamento_texto(sentence):\n",
        "\n",
        "  #remove as quebras de linha\n",
        "  sentence = re.sub(r'\\n', '', sentence)\n",
        "  #substitui tabulações por um espaço em branco\n",
        "  sentence = re.sub(r'\\t', ' ', sentence)\n",
        "  #substitui um ou mais espaços em branco por um espaço\n",
        "  sentence= re.sub(r'\\s+', ' ', sentence, flags=re.I)\n",
        "  #remove aspas e apóstofres\n",
        "  sentence = re.sub('[\"‘’“”…]', '', sentence)  \n",
        "\n",
        "  #Principais remoções\n",
        "  sentence = sentence.replace('\\\\r', '')\n",
        "  sentence = sentence.replace('\\\\n', '')\n",
        "  \n",
        "  #remove o b'\n",
        "  sentence = sentence.replace(\"b'\", \"\")\n",
        "  sentence = sentence.replace(\"''\", \"\")\n",
        "  #remove o \\r\\n'\n",
        "  sentence= re.sub(\"[\\r\\n']\", ' ', sentence)\n",
        "  sentence= re.sub(\"[\\r\\n]\", ' ', sentence) \n",
        "\n",
        "  sentence= re.sub(\"[!,]\", ' ', sentence)\n",
        "  sentence= re.sub(\"[!.]\", ' ', sentence) \n",
        "  sentence= re.sub(\"[?.]\", ' ', sentence)\n",
        "  sentence= re.sub(\"[?,]\", ' ', sentence) \n",
        "\n",
        "  return sentence\n",
        "\n",
        "#cria uma nova coluna no dataframe 'sentence' com cada sentence tokenizado\n",
        "df['message_tratado'] = df['message'].apply(tratamento_texto)\n",
        "df['response_tratado'] = df['response'].apply(tratamento_texto)\n",
        "#Exibe o resultado\n",
        "df[df.columns[::-1]].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response_tratado</th>\n",
              "      <th>message_tratado</th>\n",
              "      <th>entailment_label</th>\n",
              "      <th>response</th>\n",
              "      <th>message</th>\n",
              "      <th>pair_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i have and i am so in love with the trailer al...</td>\n",
              "      <td>have you heard of the upcoming black panther m...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'i have and i am so in love with the trailer ...</td>\n",
              "      <td>b'have you heard of the upcoming black panther...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>chadwick really is a good actor for black pant...</td>\n",
              "      <td>it looks remarkable so far</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'chadwick really is a good actor for black pa...</td>\n",
              "      <td>b'it looks remarkable so far!\\r\\n'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the trailer was kind of sad though</td>\n",
              "      <td>i agree   he really is suitable for the role</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'the trailer was kind of sad though.\\r\\n'</td>\n",
              "      <td>b'i agree!. he really is suitable for the role...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yes  it did  but i hope he become one of the b...</td>\n",
              "      <td>how so  did it bother you when his father died</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'yes, it did, but i hope he become one of the...</td>\n",
              "      <td>b'how so? did it bother you when his father di...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>but the movie will be a while until it is rele...</td>\n",
              "      <td>i second that statement</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'but the movie will be a while until it is re...</td>\n",
              "      <td>b'i second that statement!\\r\\n'</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    response_tratado  ... pair_ID\n",
              "0  i have and i am so in love with the trailer al...  ...       0\n",
              "1  chadwick really is a good actor for black pant...  ...       1\n",
              "2               the trailer was kind of sad though    ...       2\n",
              "3  yes  it did  but i hope he become one of the b...  ...       3\n",
              "4  but the movie will be a while until it is rele...  ...       4\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "cj2r7AChIAvd",
        "outputId": "cc5515d3-5430-43e0-eefe-550666f57e23"
      },
      "source": [
        "#Funcao para separar as sentenças\n",
        "def separa_sentencas(texto):\n",
        "  lista_sentencas = sent_tokenize(texto)\n",
        "  nova_lista = []\n",
        "  for sent in lista_sentencas:\n",
        "    nova_lista.append(sent.strip())\n",
        "  return nova_lista\n",
        "\n",
        "#cria uma nova coluna no dataframe 'sentence' com cada sentence tokenizado\n",
        "df['message_em_sentencas'] = df['message_tratado'].apply(separa_sentencas)\n",
        "df['response_em_sentencas'] = df['response_tratado'].apply(separa_sentencas)\n",
        "#Exibe o resultado\n",
        "df[df.columns[::-1]].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response_em_sentencas</th>\n",
              "      <th>message_em_sentencas</th>\n",
              "      <th>response_tratado</th>\n",
              "      <th>message_tratado</th>\n",
              "      <th>entailment_label</th>\n",
              "      <th>response</th>\n",
              "      <th>message</th>\n",
              "      <th>pair_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[i have and i am so in love with the trailer a...</td>\n",
              "      <td>[have you heard of the upcoming black panther ...</td>\n",
              "      <td>i have and i am so in love with the trailer al...</td>\n",
              "      <td>have you heard of the upcoming black panther m...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'i have and i am so in love with the trailer ...</td>\n",
              "      <td>b'have you heard of the upcoming black panther...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[chadwick really is a good actor for black pan...</td>\n",
              "      <td>[it looks remarkable so far]</td>\n",
              "      <td>chadwick really is a good actor for black pant...</td>\n",
              "      <td>it looks remarkable so far</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'chadwick really is a good actor for black pa...</td>\n",
              "      <td>b'it looks remarkable so far!\\r\\n'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[the trailer was kind of sad though]</td>\n",
              "      <td>[i agree   he really is suitable for the role]</td>\n",
              "      <td>the trailer was kind of sad though</td>\n",
              "      <td>i agree   he really is suitable for the role</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'the trailer was kind of sad though.\\r\\n'</td>\n",
              "      <td>b'i agree!. he really is suitable for the role...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[yes  it did  but i hope he become one of the ...</td>\n",
              "      <td>[how so  did it bother you when his father died]</td>\n",
              "      <td>yes  it did  but i hope he become one of the b...</td>\n",
              "      <td>how so  did it bother you when his father died</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'yes, it did, but i hope he become one of the...</td>\n",
              "      <td>b'how so? did it bother you when his father di...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[but the movie will be a while until it is rel...</td>\n",
              "      <td>[i second that statement]</td>\n",
              "      <td>but the movie will be a while until it is rele...</td>\n",
              "      <td>i second that statement</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'but the movie will be a while until it is re...</td>\n",
              "      <td>b'i second that statement!\\r\\n'</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               response_em_sentencas  ... pair_ID\n",
              "0  [i have and i am so in love with the trailer a...  ...       0\n",
              "1  [chadwick really is a good actor for black pan...  ...       1\n",
              "2               [the trailer was kind of sad though]  ...       2\n",
              "3  [yes  it did  but i hope he become one of the ...  ...       3\n",
              "4  [but the movie will be a while until it is rel...  ...       4\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "kpQeA0t5IA9Q",
        "outputId": "2cca04c0-a8ed-4f31-8cf6-f592d28b47c8"
      },
      "source": [
        "#Funcao para tokenizar - separar as sentenças\n",
        "def tokeniza_sentenca(lista_sentencas):\n",
        "  tokens = ''\n",
        "  for i in range (len(lista_sentencas)):\n",
        "    sentencas_unidas = \" \".join(w for w in lista_sentencas)\n",
        "    sentence = sent_tokenize(sentencas_unidas)\n",
        "    tokens = word_tokenize(sentence[i])\n",
        "  return tokens\n",
        "\n",
        "#cria uma nova coluna no dataframe 'sentence' com cada sentence tokenizado\n",
        "df['message_tokenizado'] = df['message_em_sentencas'].apply(tokeniza_sentenca)\n",
        "df['response_tokenizado'] = df['response_em_sentencas'].apply(tokeniza_sentenca)\n",
        "#Exibe o resultado\n",
        "df[df.columns[::-1]].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response_tokenizado</th>\n",
              "      <th>message_tokenizado</th>\n",
              "      <th>response_em_sentencas</th>\n",
              "      <th>message_em_sentencas</th>\n",
              "      <th>response_tratado</th>\n",
              "      <th>message_tratado</th>\n",
              "      <th>entailment_label</th>\n",
              "      <th>response</th>\n",
              "      <th>message</th>\n",
              "      <th>pair_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[i, have, and, i, am, so, in, love, with, the,...</td>\n",
              "      <td>[have, you, heard, of, the, upcoming, black, p...</td>\n",
              "      <td>[i have and i am so in love with the trailer a...</td>\n",
              "      <td>[have you heard of the upcoming black panther ...</td>\n",
              "      <td>i have and i am so in love with the trailer al...</td>\n",
              "      <td>have you heard of the upcoming black panther m...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'i have and i am so in love with the trailer ...</td>\n",
              "      <td>b'have you heard of the upcoming black panther...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[chadwick, really, is, a, good, actor, for, bl...</td>\n",
              "      <td>[it, looks, remarkable, so, far]</td>\n",
              "      <td>[chadwick really is a good actor for black pan...</td>\n",
              "      <td>[it looks remarkable so far]</td>\n",
              "      <td>chadwick really is a good actor for black pant...</td>\n",
              "      <td>it looks remarkable so far</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'chadwick really is a good actor for black pa...</td>\n",
              "      <td>b'it looks remarkable so far!\\r\\n'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[the, trailer, was, kind, of, sad, though]</td>\n",
              "      <td>[i, agree, he, really, is, suitable, for, the,...</td>\n",
              "      <td>[the trailer was kind of sad though]</td>\n",
              "      <td>[i agree   he really is suitable for the role]</td>\n",
              "      <td>the trailer was kind of sad though</td>\n",
              "      <td>i agree   he really is suitable for the role</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'the trailer was kind of sad though.\\r\\n'</td>\n",
              "      <td>b'i agree!. he really is suitable for the role...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[yes, it, did, but, i, hope, he, become, one, ...</td>\n",
              "      <td>[how, so, did, it, bother, you, when, his, fat...</td>\n",
              "      <td>[yes  it did  but i hope he become one of the ...</td>\n",
              "      <td>[how so  did it bother you when his father died]</td>\n",
              "      <td>yes  it did  but i hope he become one of the b...</td>\n",
              "      <td>how so  did it bother you when his father died</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'yes, it did, but i hope he become one of the...</td>\n",
              "      <td>b'how so? did it bother you when his father di...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[but, the, movie, will, be, a, while, until, i...</td>\n",
              "      <td>[i, second, that, statement]</td>\n",
              "      <td>[but the movie will be a while until it is rel...</td>\n",
              "      <td>[i second that statement]</td>\n",
              "      <td>but the movie will be a while until it is rele...</td>\n",
              "      <td>i second that statement</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'but the movie will be a while until it is re...</td>\n",
              "      <td>b'i second that statement!\\r\\n'</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 response_tokenizado  ... pair_ID\n",
              "0  [i, have, and, i, am, so, in, love, with, the,...  ...       0\n",
              "1  [chadwick, really, is, a, good, actor, for, bl...  ...       1\n",
              "2         [the, trailer, was, kind, of, sad, though]  ...       2\n",
              "3  [yes, it, did, but, i, hope, he, become, one, ...  ...       3\n",
              "4  [but, the, movie, will, be, a, while, until, i...  ...       4\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "J_89o7xmIBBH",
        "outputId": "b83f4cea-2288-4d16-9080-8db75fb6b147"
      },
      "source": [
        "#Remover palavras que não são importantes para a contabilizaçao\n",
        "def remove_stop_words(lista_tokens):\n",
        "  stopwords = sw.words('english')\n",
        "  stop_words = set(stopwords + list(string.punctuation))\n",
        "  tokens = [w for w in lista_tokens if not w in stop_words]\n",
        "  return tokens\n",
        "\n",
        "#cria uma nova coluna no dataframe sem stopwords\n",
        "df['message_sem_stopwords'] = df['message_tokenizado'].apply(remove_stop_words)\n",
        "df['response_sem_stopwords'] = df['response_tokenizado'].apply(remove_stop_words)\n",
        "#Exibe o resultado\n",
        "df[df.columns[::-1]].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response_sem_stopwords</th>\n",
              "      <th>message_sem_stopwords</th>\n",
              "      <th>response_tokenizado</th>\n",
              "      <th>message_tokenizado</th>\n",
              "      <th>response_em_sentencas</th>\n",
              "      <th>message_em_sentencas</th>\n",
              "      <th>response_tratado</th>\n",
              "      <th>message_tratado</th>\n",
              "      <th>entailment_label</th>\n",
              "      <th>response</th>\n",
              "      <th>message</th>\n",
              "      <th>pair_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[love, trailer, already]</td>\n",
              "      <td>[heard, upcoming, black, panther, movie]</td>\n",
              "      <td>[i, have, and, i, am, so, in, love, with, the,...</td>\n",
              "      <td>[have, you, heard, of, the, upcoming, black, p...</td>\n",
              "      <td>[i have and i am so in love with the trailer a...</td>\n",
              "      <td>[have you heard of the upcoming black panther ...</td>\n",
              "      <td>i have and i am so in love with the trailer al...</td>\n",
              "      <td>have you heard of the upcoming black panther m...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'i have and i am so in love with the trailer ...</td>\n",
              "      <td>b'have you heard of the upcoming black panther...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[chadwick, really, good, actor, black, panther]</td>\n",
              "      <td>[looks, remarkable, far]</td>\n",
              "      <td>[chadwick, really, is, a, good, actor, for, bl...</td>\n",
              "      <td>[it, looks, remarkable, so, far]</td>\n",
              "      <td>[chadwick really is a good actor for black pan...</td>\n",
              "      <td>[it looks remarkable so far]</td>\n",
              "      <td>chadwick really is a good actor for black pant...</td>\n",
              "      <td>it looks remarkable so far</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'chadwick really is a good actor for black pa...</td>\n",
              "      <td>b'it looks remarkable so far!\\r\\n'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agree, really, suitable, role]</td>\n",
              "      <td>[the, trailer, was, kind, of, sad, though]</td>\n",
              "      <td>[i, agree, he, really, is, suitable, for, the,...</td>\n",
              "      <td>[the trailer was kind of sad though]</td>\n",
              "      <td>[i agree   he really is suitable for the role]</td>\n",
              "      <td>the trailer was kind of sad though</td>\n",
              "      <td>i agree   he really is suitable for the role</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'the trailer was kind of sad though.\\r\\n'</td>\n",
              "      <td>b'i agree!. he really is suitable for the role...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[yes, hope, become, one, best, super, heroes]</td>\n",
              "      <td>[bother, father, died]</td>\n",
              "      <td>[yes, it, did, but, i, hope, he, become, one, ...</td>\n",
              "      <td>[how, so, did, it, bother, you, when, his, fat...</td>\n",
              "      <td>[yes  it did  but i hope he become one of the ...</td>\n",
              "      <td>[how so  did it bother you when his father died]</td>\n",
              "      <td>yes  it did  but i hope he become one of the b...</td>\n",
              "      <td>how so  did it bother you when his father died</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'yes, it did, but i hope he become one of the...</td>\n",
              "      <td>b'how so? did it bother you when his father di...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[movie, released, lets, hope, good, trailer, s...</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[but, the, movie, will, be, a, while, until, i...</td>\n",
              "      <td>[i, second, that, statement]</td>\n",
              "      <td>[but the movie will be a while until it is rel...</td>\n",
              "      <td>[i second that statement]</td>\n",
              "      <td>but the movie will be a while until it is rele...</td>\n",
              "      <td>i second that statement</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'but the movie will be a while until it is re...</td>\n",
              "      <td>b'i second that statement!\\r\\n'</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              response_sem_stopwords  ... pair_ID\n",
              "0                           [love, trailer, already]  ...       0\n",
              "1    [chadwick, really, good, actor, black, panther]  ...       1\n",
              "2                       [trailer, kind, sad, though]  ...       2\n",
              "3      [yes, hope, become, one, best, super, heroes]  ...       3\n",
              "4  [movie, released, lets, hope, good, trailer, s...  ...       4\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "upMBmwpzIBEN",
        "outputId": "9cc62ef9-7112-44ef-ef30-9b1526e87a79"
      },
      "source": [
        "#Funcao para o POS TAGGING \n",
        "def Postagging(sentence):\n",
        "    phrase = []\n",
        "    for word in sentence:\n",
        "        phrase.append(nltk.pos_tag(word.lower()))\n",
        "    return phrase\n",
        "\n",
        "#cria uma nova coluna no dataframe com o Postagging\n",
        "df['message_postagging'] = df['message_sem_stopwords'].apply(Postagging)\n",
        "df['response_postagging'] = df['response_sem_stopwords'].apply(Postagging)\n",
        "#Exibe o resultado\n",
        "df[df.columns[::-1]].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response_postagging</th>\n",
              "      <th>message_postagging</th>\n",
              "      <th>response_sem_stopwords</th>\n",
              "      <th>message_sem_stopwords</th>\n",
              "      <th>response_tokenizado</th>\n",
              "      <th>message_tokenizado</th>\n",
              "      <th>response_em_sentencas</th>\n",
              "      <th>message_em_sentencas</th>\n",
              "      <th>response_tratado</th>\n",
              "      <th>message_tratado</th>\n",
              "      <th>entailment_label</th>\n",
              "      <th>response</th>\n",
              "      <th>message</th>\n",
              "      <th>pair_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[(l, NN), (o, MD), (v, VB), (e, NN)], [(t, NN...</td>\n",
              "      <td>[[(h, NN), (e, VBZ), (a, DT), (r, NN), (d, NN)...</td>\n",
              "      <td>[love, trailer, already]</td>\n",
              "      <td>[heard, upcoming, black, panther, movie]</td>\n",
              "      <td>[i, have, and, i, am, so, in, love, with, the,...</td>\n",
              "      <td>[have, you, heard, of, the, upcoming, black, p...</td>\n",
              "      <td>[i have and i am so in love with the trailer a...</td>\n",
              "      <td>[have you heard of the upcoming black panther ...</td>\n",
              "      <td>i have and i am so in love with the trailer al...</td>\n",
              "      <td>have you heard of the upcoming black panther m...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'i have and i am so in love with the trailer ...</td>\n",
              "      <td>b'have you heard of the upcoming black panther...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[(c, NNS), (h, VBP), (a, DT), (d, NN), (w, NN...</td>\n",
              "      <td>[[(l, NN), (o, MD), (o, VB), (k, NN), (s, NN)]...</td>\n",
              "      <td>[chadwick, really, good, actor, black, panther]</td>\n",
              "      <td>[looks, remarkable, far]</td>\n",
              "      <td>[chadwick, really, is, a, good, actor, for, bl...</td>\n",
              "      <td>[it, looks, remarkable, so, far]</td>\n",
              "      <td>[chadwick really is a good actor for black pan...</td>\n",
              "      <td>[it looks remarkable so far]</td>\n",
              "      <td>chadwick really is a good actor for black pant...</td>\n",
              "      <td>it looks remarkable so far</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'chadwick really is a good actor for black pa...</td>\n",
              "      <td>b'it looks remarkable so far!\\r\\n'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[(t, NN), (r, VBZ), (a, DT), (i, JJ), (l, NN)...</td>\n",
              "      <td>[[(a, DT), (g, NN), (r, NN), (e, NN), (e, NN)]...</td>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agree, really, suitable, role]</td>\n",
              "      <td>[the, trailer, was, kind, of, sad, though]</td>\n",
              "      <td>[i, agree, he, really, is, suitable, for, the,...</td>\n",
              "      <td>[the trailer was kind of sad though]</td>\n",
              "      <td>[i agree   he really is suitable for the role]</td>\n",
              "      <td>the trailer was kind of sad though</td>\n",
              "      <td>i agree   he really is suitable for the role</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'the trailer was kind of sad though.\\r\\n'</td>\n",
              "      <td>b'i agree!. he really is suitable for the role...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[(y, NN), (e, NN), (s, NN)], [(h, NN), (o, MD...</td>\n",
              "      <td>[[(b, NN), (o, NN), (t, NN), (h, NN), (e, NN),...</td>\n",
              "      <td>[yes, hope, become, one, best, super, heroes]</td>\n",
              "      <td>[bother, father, died]</td>\n",
              "      <td>[yes, it, did, but, i, hope, he, become, one, ...</td>\n",
              "      <td>[how, so, did, it, bother, you, when, his, fat...</td>\n",
              "      <td>[yes  it did  but i hope he become one of the ...</td>\n",
              "      <td>[how so  did it bother you when his father died]</td>\n",
              "      <td>yes  it did  but i hope he become one of the b...</td>\n",
              "      <td>how so  did it bother you when his father died</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'yes, it did, but i hope he become one of the...</td>\n",
              "      <td>b'how so? did it bother you when his father di...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[(m, NN), (o, IN), (v, NN), (i, NN), (e, VBP)...</td>\n",
              "      <td>[[(s, NN), (e, NN), (c, VBP), (o, JJ), (n, JJ)...</td>\n",
              "      <td>[movie, released, lets, hope, good, trailer, s...</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[but, the, movie, will, be, a, while, until, i...</td>\n",
              "      <td>[i, second, that, statement]</td>\n",
              "      <td>[but the movie will be a while until it is rel...</td>\n",
              "      <td>[i second that statement]</td>\n",
              "      <td>but the movie will be a while until it is rele...</td>\n",
              "      <td>i second that statement</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'but the movie will be a while until it is re...</td>\n",
              "      <td>b'i second that statement!\\r\\n'</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 response_postagging  ... pair_ID\n",
              "0  [[(l, NN), (o, MD), (v, VB), (e, NN)], [(t, NN...  ...       0\n",
              "1  [[(c, NNS), (h, VBP), (a, DT), (d, NN), (w, NN...  ...       1\n",
              "2  [[(t, NN), (r, VBZ), (a, DT), (i, JJ), (l, NN)...  ...       2\n",
              "3  [[(y, NN), (e, NN), (s, NN)], [(h, NN), (o, MD...  ...       3\n",
              "4  [[(m, NN), (o, IN), (v, NN), (i, NN), (e, VBP)...  ...       4\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "_sdzw28qIBHT",
        "outputId": "1579532d-679e-45d1-87f9-8610dc6ef43e"
      },
      "source": [
        "#Funcao para stemmingzar (tratar o radical da palavra, até a origem)\n",
        "def Stemming(sentence):\n",
        "    stemmer = PorterStemmer()\n",
        "    phrase = []\n",
        "    for word in sentence:\n",
        "        phrase.append(stemmer.stem(word.lower()))\n",
        "    return phrase\n",
        "\n",
        "#cria uma nova coluna no dataframe com a raiz de tokens\n",
        "df['message_raiz'] = df['message_sem_stopwords'].apply(Stemming)\n",
        "df['response_raiz'] = df['response_sem_stopwords'].apply(Stemming)\n",
        "#Exibe o resultado\n",
        "df[df.columns[::-1]].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response_raiz</th>\n",
              "      <th>message_raiz</th>\n",
              "      <th>response_postagging</th>\n",
              "      <th>message_postagging</th>\n",
              "      <th>response_sem_stopwords</th>\n",
              "      <th>message_sem_stopwords</th>\n",
              "      <th>response_tokenizado</th>\n",
              "      <th>message_tokenizado</th>\n",
              "      <th>response_em_sentencas</th>\n",
              "      <th>message_em_sentencas</th>\n",
              "      <th>response_tratado</th>\n",
              "      <th>message_tratado</th>\n",
              "      <th>entailment_label</th>\n",
              "      <th>response</th>\n",
              "      <th>message</th>\n",
              "      <th>pair_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[love, trailer, alreadi]</td>\n",
              "      <td>[heard, upcom, black, panther, movi]</td>\n",
              "      <td>[[(l, NN), (o, MD), (v, VB), (e, NN)], [(t, NN...</td>\n",
              "      <td>[[(h, NN), (e, VBZ), (a, DT), (r, NN), (d, NN)...</td>\n",
              "      <td>[love, trailer, already]</td>\n",
              "      <td>[heard, upcoming, black, panther, movie]</td>\n",
              "      <td>[i, have, and, i, am, so, in, love, with, the,...</td>\n",
              "      <td>[have, you, heard, of, the, upcoming, black, p...</td>\n",
              "      <td>[i have and i am so in love with the trailer a...</td>\n",
              "      <td>[have you heard of the upcoming black panther ...</td>\n",
              "      <td>i have and i am so in love with the trailer al...</td>\n",
              "      <td>have you heard of the upcoming black panther m...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'i have and i am so in love with the trailer ...</td>\n",
              "      <td>b'have you heard of the upcoming black panther...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[chadwick, realli, good, actor, black, panther]</td>\n",
              "      <td>[look, remark, far]</td>\n",
              "      <td>[[(c, NNS), (h, VBP), (a, DT), (d, NN), (w, NN...</td>\n",
              "      <td>[[(l, NN), (o, MD), (o, VB), (k, NN), (s, NN)]...</td>\n",
              "      <td>[chadwick, really, good, actor, black, panther]</td>\n",
              "      <td>[looks, remarkable, far]</td>\n",
              "      <td>[chadwick, really, is, a, good, actor, for, bl...</td>\n",
              "      <td>[it, looks, remarkable, so, far]</td>\n",
              "      <td>[chadwick really is a good actor for black pan...</td>\n",
              "      <td>[it looks remarkable so far]</td>\n",
              "      <td>chadwick really is a good actor for black pant...</td>\n",
              "      <td>it looks remarkable so far</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'chadwick really is a good actor for black pa...</td>\n",
              "      <td>b'it looks remarkable so far!\\r\\n'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agre, realli, suitabl, role]</td>\n",
              "      <td>[[(t, NN), (r, VBZ), (a, DT), (i, JJ), (l, NN)...</td>\n",
              "      <td>[[(a, DT), (g, NN), (r, NN), (e, NN), (e, NN)]...</td>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agree, really, suitable, role]</td>\n",
              "      <td>[the, trailer, was, kind, of, sad, though]</td>\n",
              "      <td>[i, agree, he, really, is, suitable, for, the,...</td>\n",
              "      <td>[the trailer was kind of sad though]</td>\n",
              "      <td>[i agree   he really is suitable for the role]</td>\n",
              "      <td>the trailer was kind of sad though</td>\n",
              "      <td>i agree   he really is suitable for the role</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'the trailer was kind of sad though.\\r\\n'</td>\n",
              "      <td>b'i agree!. he really is suitable for the role...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[ye, hope, becom, one, best, super, hero]</td>\n",
              "      <td>[bother, father, die]</td>\n",
              "      <td>[[(y, NN), (e, NN), (s, NN)], [(h, NN), (o, MD...</td>\n",
              "      <td>[[(b, NN), (o, NN), (t, NN), (h, NN), (e, NN),...</td>\n",
              "      <td>[yes, hope, become, one, best, super, heroes]</td>\n",
              "      <td>[bother, father, died]</td>\n",
              "      <td>[yes, it, did, but, i, hope, he, become, one, ...</td>\n",
              "      <td>[how, so, did, it, bother, you, when, his, fat...</td>\n",
              "      <td>[yes  it did  but i hope he become one of the ...</td>\n",
              "      <td>[how so  did it bother you when his father died]</td>\n",
              "      <td>yes  it did  but i hope he become one of the b...</td>\n",
              "      <td>how so  did it bother you when his father died</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'yes, it did, but i hope he become one of the...</td>\n",
              "      <td>b'how so? did it bother you when his father di...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[movi, releas, let, hope, good, trailer, show,...</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[[(m, NN), (o, IN), (v, NN), (i, NN), (e, VBP)...</td>\n",
              "      <td>[[(s, NN), (e, NN), (c, VBP), (o, JJ), (n, JJ)...</td>\n",
              "      <td>[movie, released, lets, hope, good, trailer, s...</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[but, the, movie, will, be, a, while, until, i...</td>\n",
              "      <td>[i, second, that, statement]</td>\n",
              "      <td>[but the movie will be a while until it is rel...</td>\n",
              "      <td>[i second that statement]</td>\n",
              "      <td>but the movie will be a while until it is rele...</td>\n",
              "      <td>i second that statement</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'but the movie will be a while until it is re...</td>\n",
              "      <td>b'i second that statement!\\r\\n'</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       response_raiz  ... pair_ID\n",
              "0                           [love, trailer, alreadi]  ...       0\n",
              "1    [chadwick, realli, good, actor, black, panther]  ...       1\n",
              "2                       [trailer, kind, sad, though]  ...       2\n",
              "3          [ye, hope, becom, one, best, super, hero]  ...       3\n",
              "4  [movi, releas, let, hope, good, trailer, show,...  ...       4\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXBK8nwwJ4CB",
        "outputId": "3bd3fa67-3da9-44c3-8432-7dc33886f626"
      },
      "source": [
        "#Funcao para Lematizar: processo de agrupar formas flexionadas em uma só palavra com similar.\n",
        "def Lematizar(sentence):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    for i in range (len(sentence)):\n",
        "        words = nltk.word_tokenize(sentence[i])\n",
        "        newwords = [lemmatizer.lemmatize(word) for word in words]\n",
        "        sentence[i] = ' '.join(newwords)\n",
        "    return sentence\n",
        "\n",
        "#cria uma nova coluna com o texto com formas flexionadas\n",
        "df['message_lematizado'] = df['message_raiz'].apply(Lematizar)\n",
        "df['response_lematizado'] = df['response_raiz'].apply(Lematizar)\n",
        "#Exibe o resultado\n",
        "df[df.columns[::-1]].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response_lematizado</th>\n",
              "      <th>message_lematizado</th>\n",
              "      <th>response_raiz</th>\n",
              "      <th>message_raiz</th>\n",
              "      <th>response_postagging</th>\n",
              "      <th>message_postagging</th>\n",
              "      <th>response_sem_stopwords</th>\n",
              "      <th>message_sem_stopwords</th>\n",
              "      <th>response_tokenizado</th>\n",
              "      <th>message_tokenizado</th>\n",
              "      <th>response_em_sentencas</th>\n",
              "      <th>message_em_sentencas</th>\n",
              "      <th>response_tratado</th>\n",
              "      <th>message_tratado</th>\n",
              "      <th>entailment_label</th>\n",
              "      <th>response</th>\n",
              "      <th>message</th>\n",
              "      <th>pair_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[love, trailer, alreadi]</td>\n",
              "      <td>[heard, upcom, black, panther, movi]</td>\n",
              "      <td>[love, trailer, alreadi]</td>\n",
              "      <td>[heard, upcom, black, panther, movi]</td>\n",
              "      <td>[[(l, NN), (o, MD), (v, VB), (e, NN)], [(t, NN...</td>\n",
              "      <td>[[(h, NN), (e, VBZ), (a, DT), (r, NN), (d, NN)...</td>\n",
              "      <td>[love, trailer, already]</td>\n",
              "      <td>[heard, upcoming, black, panther, movie]</td>\n",
              "      <td>[i, have, and, i, am, so, in, love, with, the,...</td>\n",
              "      <td>[have, you, heard, of, the, upcoming, black, p...</td>\n",
              "      <td>[i have and i am so in love with the trailer a...</td>\n",
              "      <td>[have you heard of the upcoming black panther ...</td>\n",
              "      <td>i have and i am so in love with the trailer al...</td>\n",
              "      <td>have you heard of the upcoming black panther m...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'i have and i am so in love with the trailer ...</td>\n",
              "      <td>b'have you heard of the upcoming black panther...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[chadwick, realli, good, actor, black, panther]</td>\n",
              "      <td>[look, remark, far]</td>\n",
              "      <td>[chadwick, realli, good, actor, black, panther]</td>\n",
              "      <td>[look, remark, far]</td>\n",
              "      <td>[[(c, NNS), (h, VBP), (a, DT), (d, NN), (w, NN...</td>\n",
              "      <td>[[(l, NN), (o, MD), (o, VB), (k, NN), (s, NN)]...</td>\n",
              "      <td>[chadwick, really, good, actor, black, panther]</td>\n",
              "      <td>[looks, remarkable, far]</td>\n",
              "      <td>[chadwick, really, is, a, good, actor, for, bl...</td>\n",
              "      <td>[it, looks, remarkable, so, far]</td>\n",
              "      <td>[chadwick really is a good actor for black pan...</td>\n",
              "      <td>[it looks remarkable so far]</td>\n",
              "      <td>chadwick really is a good actor for black pant...</td>\n",
              "      <td>it looks remarkable so far</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'chadwick really is a good actor for black pa...</td>\n",
              "      <td>b'it looks remarkable so far!\\r\\n'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agre, realli, suitabl, role]</td>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agre, realli, suitabl, role]</td>\n",
              "      <td>[[(t, NN), (r, VBZ), (a, DT), (i, JJ), (l, NN)...</td>\n",
              "      <td>[[(a, DT), (g, NN), (r, NN), (e, NN), (e, NN)]...</td>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agree, really, suitable, role]</td>\n",
              "      <td>[the, trailer, was, kind, of, sad, though]</td>\n",
              "      <td>[i, agree, he, really, is, suitable, for, the,...</td>\n",
              "      <td>[the trailer was kind of sad though]</td>\n",
              "      <td>[i agree   he really is suitable for the role]</td>\n",
              "      <td>the trailer was kind of sad though</td>\n",
              "      <td>i agree   he really is suitable for the role</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'the trailer was kind of sad though.\\r\\n'</td>\n",
              "      <td>b'i agree!. he really is suitable for the role...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[ye, hope, becom, one, best, super, hero]</td>\n",
              "      <td>[bother, father, die]</td>\n",
              "      <td>[ye, hope, becom, one, best, super, hero]</td>\n",
              "      <td>[bother, father, die]</td>\n",
              "      <td>[[(y, NN), (e, NN), (s, NN)], [(h, NN), (o, MD...</td>\n",
              "      <td>[[(b, NN), (o, NN), (t, NN), (h, NN), (e, NN),...</td>\n",
              "      <td>[yes, hope, become, one, best, super, heroes]</td>\n",
              "      <td>[bother, father, died]</td>\n",
              "      <td>[yes, it, did, but, i, hope, he, become, one, ...</td>\n",
              "      <td>[how, so, did, it, bother, you, when, his, fat...</td>\n",
              "      <td>[yes  it did  but i hope he become one of the ...</td>\n",
              "      <td>[how so  did it bother you when his father died]</td>\n",
              "      <td>yes  it did  but i hope he become one of the b...</td>\n",
              "      <td>how so  did it bother you when his father died</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'yes, it did, but i hope he become one of the...</td>\n",
              "      <td>b'how so? did it bother you when his father di...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[movi, releas, let, hope, good, trailer, show, u]</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[movi, releas, let, hope, good, trailer, show, u]</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[[(m, NN), (o, IN), (v, NN), (i, NN), (e, VBP)...</td>\n",
              "      <td>[[(s, NN), (e, NN), (c, VBP), (o, JJ), (n, JJ)...</td>\n",
              "      <td>[movie, released, lets, hope, good, trailer, s...</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[but, the, movie, will, be, a, while, until, i...</td>\n",
              "      <td>[i, second, that, statement]</td>\n",
              "      <td>[but the movie will be a while until it is rel...</td>\n",
              "      <td>[i second that statement]</td>\n",
              "      <td>but the movie will be a while until it is rele...</td>\n",
              "      <td>i second that statement</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'but the movie will be a while until it is re...</td>\n",
              "      <td>b'i second that statement!\\r\\n'</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 response_lematizado  ... pair_ID\n",
              "0                           [love, trailer, alreadi]  ...       0\n",
              "1    [chadwick, realli, good, actor, black, panther]  ...       1\n",
              "2                       [trailer, kind, sad, though]  ...       2\n",
              "3          [ye, hope, becom, one, best, super, hero]  ...       3\n",
              "4  [movi, releas, let, hope, good, trailer, show, u]  ...       4\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "FXmx8qQSJ4FJ",
        "outputId": "264cb296-3fff-40f0-b116-137d532a97a2"
      },
      "source": [
        "#Funcao para aplicar o LER nas setencas\n",
        "def Ner(sentence):\n",
        "    doc = nlp(sentence) \n",
        "    phrase = []\n",
        "    for ent in doc.ents:\n",
        "        phrase.append(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
        "    return phrase\n",
        "\n",
        "#cria uma nova coluna com o texto com as entidades identificadas\n",
        "df['message_NER'] = df['message_lematizado'].apply(Lematizar)\n",
        "df['response_NER'] = df['response_lematizado'].apply(Lematizar)\n",
        "#Exibe o resultado\n",
        "df[df.columns[::-1]].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response_NER</th>\n",
              "      <th>message_NER</th>\n",
              "      <th>response_lematizado</th>\n",
              "      <th>message_lematizado</th>\n",
              "      <th>response_raiz</th>\n",
              "      <th>message_raiz</th>\n",
              "      <th>response_postagging</th>\n",
              "      <th>message_postagging</th>\n",
              "      <th>response_sem_stopwords</th>\n",
              "      <th>message_sem_stopwords</th>\n",
              "      <th>response_tokenizado</th>\n",
              "      <th>message_tokenizado</th>\n",
              "      <th>response_em_sentencas</th>\n",
              "      <th>message_em_sentencas</th>\n",
              "      <th>response_tratado</th>\n",
              "      <th>message_tratado</th>\n",
              "      <th>entailment_label</th>\n",
              "      <th>response</th>\n",
              "      <th>message</th>\n",
              "      <th>pair_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[love, trailer, alreadi]</td>\n",
              "      <td>[heard, upcom, black, panther, movi]</td>\n",
              "      <td>[love, trailer, alreadi]</td>\n",
              "      <td>[heard, upcom, black, panther, movi]</td>\n",
              "      <td>[love, trailer, alreadi]</td>\n",
              "      <td>[heard, upcom, black, panther, movi]</td>\n",
              "      <td>[[(l, NN), (o, MD), (v, VB), (e, NN)], [(t, NN...</td>\n",
              "      <td>[[(h, NN), (e, VBZ), (a, DT), (r, NN), (d, NN)...</td>\n",
              "      <td>[love, trailer, already]</td>\n",
              "      <td>[heard, upcoming, black, panther, movie]</td>\n",
              "      <td>[i, have, and, i, am, so, in, love, with, the,...</td>\n",
              "      <td>[have, you, heard, of, the, upcoming, black, p...</td>\n",
              "      <td>[i have and i am so in love with the trailer a...</td>\n",
              "      <td>[have you heard of the upcoming black panther ...</td>\n",
              "      <td>i have and i am so in love with the trailer al...</td>\n",
              "      <td>have you heard of the upcoming black panther m...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'i have and i am so in love with the trailer ...</td>\n",
              "      <td>b'have you heard of the upcoming black panther...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[chadwick, realli, good, actor, black, panther]</td>\n",
              "      <td>[look, remark, far]</td>\n",
              "      <td>[chadwick, realli, good, actor, black, panther]</td>\n",
              "      <td>[look, remark, far]</td>\n",
              "      <td>[chadwick, realli, good, actor, black, panther]</td>\n",
              "      <td>[look, remark, far]</td>\n",
              "      <td>[[(c, NNS), (h, VBP), (a, DT), (d, NN), (w, NN...</td>\n",
              "      <td>[[(l, NN), (o, MD), (o, VB), (k, NN), (s, NN)]...</td>\n",
              "      <td>[chadwick, really, good, actor, black, panther]</td>\n",
              "      <td>[looks, remarkable, far]</td>\n",
              "      <td>[chadwick, really, is, a, good, actor, for, bl...</td>\n",
              "      <td>[it, looks, remarkable, so, far]</td>\n",
              "      <td>[chadwick really is a good actor for black pan...</td>\n",
              "      <td>[it looks remarkable so far]</td>\n",
              "      <td>chadwick really is a good actor for black pant...</td>\n",
              "      <td>it looks remarkable so far</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'chadwick really is a good actor for black pa...</td>\n",
              "      <td>b'it looks remarkable so far!\\r\\n'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agre, realli, suitabl, role]</td>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agre, realli, suitabl, role]</td>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agre, realli, suitabl, role]</td>\n",
              "      <td>[[(t, NN), (r, VBZ), (a, DT), (i, JJ), (l, NN)...</td>\n",
              "      <td>[[(a, DT), (g, NN), (r, NN), (e, NN), (e, NN)]...</td>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agree, really, suitable, role]</td>\n",
              "      <td>[the, trailer, was, kind, of, sad, though]</td>\n",
              "      <td>[i, agree, he, really, is, suitable, for, the,...</td>\n",
              "      <td>[the trailer was kind of sad though]</td>\n",
              "      <td>[i agree   he really is suitable for the role]</td>\n",
              "      <td>the trailer was kind of sad though</td>\n",
              "      <td>i agree   he really is suitable for the role</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'the trailer was kind of sad though.\\r\\n'</td>\n",
              "      <td>b'i agree!. he really is suitable for the role...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[ye, hope, becom, one, best, super, hero]</td>\n",
              "      <td>[bother, father, die]</td>\n",
              "      <td>[ye, hope, becom, one, best, super, hero]</td>\n",
              "      <td>[bother, father, die]</td>\n",
              "      <td>[ye, hope, becom, one, best, super, hero]</td>\n",
              "      <td>[bother, father, die]</td>\n",
              "      <td>[[(y, NN), (e, NN), (s, NN)], [(h, NN), (o, MD...</td>\n",
              "      <td>[[(b, NN), (o, NN), (t, NN), (h, NN), (e, NN),...</td>\n",
              "      <td>[yes, hope, become, one, best, super, heroes]</td>\n",
              "      <td>[bother, father, died]</td>\n",
              "      <td>[yes, it, did, but, i, hope, he, become, one, ...</td>\n",
              "      <td>[how, so, did, it, bother, you, when, his, fat...</td>\n",
              "      <td>[yes  it did  but i hope he become one of the ...</td>\n",
              "      <td>[how so  did it bother you when his father died]</td>\n",
              "      <td>yes  it did  but i hope he become one of the b...</td>\n",
              "      <td>how so  did it bother you when his father died</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'yes, it did, but i hope he become one of the...</td>\n",
              "      <td>b'how so? did it bother you when his father di...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[movi, releas, let, hope, good, trailer, show, u]</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[movi, releas, let, hope, good, trailer, show, u]</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[movi, releas, let, hope, good, trailer, show, u]</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[[(m, NN), (o, IN), (v, NN), (i, NN), (e, VBP)...</td>\n",
              "      <td>[[(s, NN), (e, NN), (c, VBP), (o, JJ), (n, JJ)...</td>\n",
              "      <td>[movie, released, lets, hope, good, trailer, s...</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[but, the, movie, will, be, a, while, until, i...</td>\n",
              "      <td>[i, second, that, statement]</td>\n",
              "      <td>[but the movie will be a while until it is rel...</td>\n",
              "      <td>[i second that statement]</td>\n",
              "      <td>but the movie will be a while until it is rele...</td>\n",
              "      <td>i second that statement</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'but the movie will be a while until it is re...</td>\n",
              "      <td>b'i second that statement!\\r\\n'</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        response_NER  ... pair_ID\n",
              "0                           [love, trailer, alreadi]  ...       0\n",
              "1    [chadwick, realli, good, actor, black, panther]  ...       1\n",
              "2                       [trailer, kind, sad, though]  ...       2\n",
              "3          [ye, hope, becom, one, best, super, hero]  ...       3\n",
              "4  [movi, releas, let, hope, good, trailer, show, u]  ...       4\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "LQi9PBnIJ4IJ",
        "outputId": "0875d35f-2513-4798-b531-077e45036348"
      },
      "source": [
        "#Funcao para aplicar a vetorização TFIDF\n",
        "def vetorizeTFIDF(corpus):\n",
        "    corpus_aux = [list(doc) for doc in corpus]\n",
        "    texts = TextCollection(corpus_aux)      \n",
        "    features = defaultdict(float)\n",
        "    for doc in corpus_aux:\n",
        "        for token in doc:\n",
        "            features[token] = texts.tf_idf(token,doc)\n",
        "    return features \n",
        "\n",
        "#cria uma nova coluna com o texto com as entidades identificadas\n",
        "df['message_vetorizado_TFIDF'] = df['message_lematizado'].apply(vetorizeTFIDF)\n",
        "df['response_vetorizado_TFIDF'] = df['response_lematizado'].apply(vetorizeTFIDF)\n",
        "#Exibe o resultado\n",
        "df[df.columns[::-1]].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response_vetorizado_TFIDF</th>\n",
              "      <th>message_vetorizado_TFIDF</th>\n",
              "      <th>response_NER</th>\n",
              "      <th>message_NER</th>\n",
              "      <th>response_lematizado</th>\n",
              "      <th>message_lematizado</th>\n",
              "      <th>response_raiz</th>\n",
              "      <th>message_raiz</th>\n",
              "      <th>response_postagging</th>\n",
              "      <th>message_postagging</th>\n",
              "      <th>response_sem_stopwords</th>\n",
              "      <th>message_sem_stopwords</th>\n",
              "      <th>response_tokenizado</th>\n",
              "      <th>message_tokenizado</th>\n",
              "      <th>response_em_sentencas</th>\n",
              "      <th>message_em_sentencas</th>\n",
              "      <th>response_tratado</th>\n",
              "      <th>message_tratado</th>\n",
              "      <th>entailment_label</th>\n",
              "      <th>response</th>\n",
              "      <th>message</th>\n",
              "      <th>pair_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'l': 0.0, 'o': 0.27465307216702745, 'v': 0.27...</td>\n",
              "      <td>{'h': 0.13089867598202215, 'e': 0.130898675982...</td>\n",
              "      <td>[love, trailer, alreadi]</td>\n",
              "      <td>[heard, upcom, black, panther, movi]</td>\n",
              "      <td>[love, trailer, alreadi]</td>\n",
              "      <td>[heard, upcom, black, panther, movi]</td>\n",
              "      <td>[love, trailer, alreadi]</td>\n",
              "      <td>[heard, upcom, black, panther, movi]</td>\n",
              "      <td>[[(l, NN), (o, MD), (v, VB), (e, NN)], [(t, NN...</td>\n",
              "      <td>[[(h, NN), (e, VBZ), (a, DT), (r, NN), (d, NN)...</td>\n",
              "      <td>[love, trailer, already]</td>\n",
              "      <td>[heard, upcoming, black, panther, movie]</td>\n",
              "      <td>[i, have, and, i, am, so, in, love, with, the,...</td>\n",
              "      <td>[have, you, heard, of, the, upcoming, black, p...</td>\n",
              "      <td>[i have and i am so in love with the trailer a...</td>\n",
              "      <td>[have you heard of the upcoming black panther ...</td>\n",
              "      <td>i have and i am so in love with the trailer al...</td>\n",
              "      <td>have you heard of the upcoming black panther m...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'i have and i am so in love with the trailer ...</td>\n",
              "      <td>b'have you heard of the upcoming black panther...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'c': 0.13862943611198905, 'h': 0.156944612666...</td>\n",
              "      <td>{'l': 0.27465307216702745, 'o': 0.549306144334...</td>\n",
              "      <td>[chadwick, realli, good, actor, black, panther]</td>\n",
              "      <td>[look, remark, far]</td>\n",
              "      <td>[chadwick, realli, good, actor, black, panther]</td>\n",
              "      <td>[look, remark, far]</td>\n",
              "      <td>[chadwick, realli, good, actor, black, panther]</td>\n",
              "      <td>[look, remark, far]</td>\n",
              "      <td>[[(c, NNS), (h, VBP), (a, DT), (d, NN), (w, NN...</td>\n",
              "      <td>[[(l, NN), (o, MD), (o, VB), (k, NN), (s, NN)]...</td>\n",
              "      <td>[chadwick, really, good, actor, black, panther]</td>\n",
              "      <td>[looks, remarkable, far]</td>\n",
              "      <td>[chadwick, really, is, a, good, actor, for, bl...</td>\n",
              "      <td>[it, looks, remarkable, so, far]</td>\n",
              "      <td>[chadwick really is a good actor for black pan...</td>\n",
              "      <td>[it looks remarkable so far]</td>\n",
              "      <td>chadwick really is a good actor for black pant...</td>\n",
              "      <td>it looks remarkable so far</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'chadwick really is a good actor for black pa...</td>\n",
              "      <td>b'it looks remarkable so far!\\r\\n'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'t': 0.11552453009332421, 'r': 0.396084103177...</td>\n",
              "      <td>{'a': 0.04109743892168297, 'g': 0.346573590279...</td>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agre, realli, suitabl, role]</td>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agre, realli, suitabl, role]</td>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agre, realli, suitabl, role]</td>\n",
              "      <td>[[(t, NN), (r, VBZ), (a, DT), (i, JJ), (l, NN)...</td>\n",
              "      <td>[[(a, DT), (g, NN), (r, NN), (e, NN), (e, NN)]...</td>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agree, really, suitable, role]</td>\n",
              "      <td>[the, trailer, was, kind, of, sad, though]</td>\n",
              "      <td>[i, agree, he, really, is, suitable, for, the,...</td>\n",
              "      <td>[the trailer was kind of sad though]</td>\n",
              "      <td>[i agree   he really is suitable for the role]</td>\n",
              "      <td>the trailer was kind of sad though</td>\n",
              "      <td>i agree   he really is suitable for the role</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'the trailer was kind of sad though.\\r\\n'</td>\n",
              "      <td>b'i agree!. he really is suitable for the role...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'y': 0.9729550745276566, 'e': 0.0, 'h': 0.313...</td>\n",
              "      <td>{'b': 0.1831020481113516, 'o': 0.1831020481113...</td>\n",
              "      <td>[ye, hope, becom, one, best, super, hero]</td>\n",
              "      <td>[bother, father, die]</td>\n",
              "      <td>[ye, hope, becom, one, best, super, hero]</td>\n",
              "      <td>[bother, father, die]</td>\n",
              "      <td>[ye, hope, becom, one, best, super, hero]</td>\n",
              "      <td>[bother, father, die]</td>\n",
              "      <td>[[(y, NN), (e, NN), (s, NN)], [(h, NN), (o, MD...</td>\n",
              "      <td>[[(b, NN), (o, NN), (t, NN), (h, NN), (e, NN),...</td>\n",
              "      <td>[yes, hope, become, one, best, super, heroes]</td>\n",
              "      <td>[bother, father, died]</td>\n",
              "      <td>[yes, it, did, but, i, hope, he, become, one, ...</td>\n",
              "      <td>[how, so, did, it, bother, you, when, his, fat...</td>\n",
              "      <td>[yes  it did  but i hope he become one of the ...</td>\n",
              "      <td>[how so  did it bother you when his father died]</td>\n",
              "      <td>yes  it did  but i hope he become one of the b...</td>\n",
              "      <td>how so  did it bother you when his father died</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'yes, it did, but i hope he become one of the...</td>\n",
              "      <td>b'how so? did it bother you when his father di...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'m': 0.5198603854199589, 'o': 0.1732867951399...</td>\n",
              "      <td>{'s': 0.0, 'e': 0.0, 'c': 0.11552453009332421,...</td>\n",
              "      <td>[movi, releas, let, hope, good, trailer, show, u]</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[movi, releas, let, hope, good, trailer, show, u]</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[movi, releas, let, hope, good, trailer, show, u]</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[[(m, NN), (o, IN), (v, NN), (i, NN), (e, VBP)...</td>\n",
              "      <td>[[(s, NN), (e, NN), (c, VBP), (o, JJ), (n, JJ)...</td>\n",
              "      <td>[movie, released, lets, hope, good, trailer, s...</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[but, the, movie, will, be, a, while, until, i...</td>\n",
              "      <td>[i, second, that, statement]</td>\n",
              "      <td>[but the movie will be a while until it is rel...</td>\n",
              "      <td>[i second that statement]</td>\n",
              "      <td>but the movie will be a while until it is rele...</td>\n",
              "      <td>i second that statement</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'but the movie will be a while until it is re...</td>\n",
              "      <td>b'i second that statement!\\r\\n'</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           response_vetorizado_TFIDF  ... pair_ID\n",
              "0  {'l': 0.0, 'o': 0.27465307216702745, 'v': 0.27...  ...       0\n",
              "1  {'c': 0.13862943611198905, 'h': 0.156944612666...  ...       1\n",
              "2  {'t': 0.11552453009332421, 'r': 0.396084103177...  ...       2\n",
              "3  {'y': 0.9729550745276566, 'e': 0.0, 'h': 0.313...  ...       3\n",
              "4  {'m': 0.5198603854199589, 'o': 0.1732867951399...  ...       4\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHqtYD9VVpst",
        "outputId": "216ea29a-ac01-472c-d4c7-6a3815e802d8"
      },
      "source": [
        "pln = spacy.load('en')\n",
        "pln"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7fea1a48b290>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbdKo2XaVpjg",
        "outputId": "0a231b2b-b224-4dd7-9e08-a00a75c374c2"
      },
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "stop_words = STOP_WORDS\n",
        "print(stop_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'yourselves', 'alone', 'so', 'n‘t', 'into', 'nothing', 'because', 'whereas', 'enough', 'further', 'itself', 'what', 'five', \"'re\", 'does', 'was', 'then', 'are', 'himself', 'too', '‘m', 'beyond', 'ourselves', 'beside', 'each', 'nine', 'forty', 'to', 'make', 'yet', 'under', 'whether', 'its', 'between', 'anywhere', 'after', \"'ll\", 'hers', 'off', 'thereupon', 'how', 'has', 'though', 'herein', 'do', 'former', 'became', 'twelve', 'call', 'whither', 'she', 'indeed', 'seems', 'i', 'eight', 'two', 'therein', 'seemed', 'three', 'your', 'hundred', 'must', 'also', 'wherever', 'every', 'he', 'amount', 'if', 'within', 'since', '’ve', 'becomes', 'there', 'show', 'part', 'eleven', 'where', 'which', 'empty', '‘re', 'another', 'seem', 'for', 'meanwhile', 'with', 'hereafter', 'onto', 'it', 'yourself', 'done', \"'ve\", 'beforehand', 'everything', 'become', 'various', 'four', 'you', 'most', '’s', 'why', 'herself', 'thus', 'before', 'they', 'many', 'other', 'nevertheless', 'although', 'n’t', 'not', 'sometimes', 'without', 'those', 'none', 'name', 'moreover', 'formerly', '’re', 'ours', 'through', 'least', 'less', 'whence', 'hereby', 'hence', 'once', 'well', 'would', 'can', \"'s\", 'ca', 'whenever', 'fifty', 'same', 'some', 'until', 'them', 'who', 'own', 'might', 'no', 'whom', 'upon', 'their', 'been', 'always', 'us', 'be', 'being', 'this', 'one', \"'m\", 'back', 'anything', 'others', 'neither', 'per', 'in', 'give', 'somewhere', 'therefore', 'any', 'will', 'may', 'should', 'the', 'now', 'sometime', 'toward', 'never', 'very', 'doing', 'throughout', 'along', 'bottom', 'thereby', 'keep', '‘d', 'and', 'am', 'nor', 'than', 'made', 'themselves', 'several', 'either', 'often', 'cannot', 'thru', 'that', 'down', 'move', 'anyway', 'go', 'mostly', 'noone', 'have', 'all', 'by', 'third', 'due', 'six', '‘s', '’ll', 'else', 'even', 'rather', 'a', 'out', 're', 'anyone', 'whole', 'me', 'from', 'using', 'were', 'used', 'unless', 'did', 'somehow', 'at', 'anyhow', '’m', 'again', 'get', 'however', 'much', 'towards', 'quite', 'here', 'latter', 'besides', 'mine', 'put', 'front', 'my', 'nobody', '‘ve', 'top', 'everyone', 'such', 'when', 'take', 'over', 'serious', 'whose', 'around', 'against', 'already', 'amongst', 'hereupon', 'side', 'via', 'someone', 'twenty', 'whereafter', 'his', 'across', 'last', 'ten', 'otherwise', 'whoever', 'an', 'full', 'seeming', 'had', 'sixty', 'together', \"n't\", 'perhaps', \"'d\", 'whatever', 'only', 'really', 'afterwards', 'just', 'few', 'everywhere', 'could', 'our', 'her', 'while', 'regarding', 'first', 'behind', 'we', 'wherein', '’d', 'him', '‘ll', 'is', 'thence', 'more', 'myself', 'see', 'or', 'these', 'becoming', 'elsewhere', 'something', 'of', 'whereupon', 'almost', 'during', 'please', 'except', 'below', 'latterly', 'nowhere', 'namely', 'ever', 'thereafter', 'whereby', 'fifteen', 'up', 'still', 'among', 'next', 'but', 'both', 'as', 'say', 'on', 'about', 'above', 'yours'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXWBRn3BVph1",
        "outputId": "77612d65-fdbf-4168-babd-1798decf93e6"
      },
      "source": [
        "pontuacoes = string.punctuation\n",
        "pontuacoes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XR-8KEAVppE",
        "outputId": "6d379a5c-3f57-439a-eb87-b2b2bee8d279"
      },
      "source": [
        "len(stop_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "yNw5oYcrVpvU",
        "outputId": "60933cc0-9a11-4683-9646-649d3e6682a9"
      },
      "source": [
        "#Outra Função para tratar o texto\n",
        "def tratamento_texto(sentence):\n",
        "  \n",
        "  #remove as quebras de linha\n",
        "  sentence = re.sub(r'\\n', '', sentence)\n",
        "  #substitui tabulações por um espaço em branco\n",
        "  sentence = re.sub(r'\\t', ' ', sentence)\n",
        "  #substitui um ou mais espaços em branco por um espaço\n",
        "  sentence= re.sub(r'\\s+', ' ', sentence, flags=re.I)\n",
        "  #&amp;\n",
        "  #remove aspas e apóstofres\n",
        "  sentence = re.sub('[\"‘’“”…]', '', sentence)\n",
        "  return sentence\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
        "    tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\n",
        "    tweet = re.sub(r\" +\", ' ', tweet)\n",
        "    return tweet\n",
        "\n",
        "def preprocessamento(texto):\n",
        "  texto = texto.lower()\n",
        "  documento = pln(texto)\n",
        "  \n",
        "  lista = []\n",
        "  for token in documento:\n",
        "    #lista.append(token.text)\n",
        "    lista.append(token.lemma_)\n",
        "\n",
        "  lista = [palavra for palavra in lista if palavra not in stop_words and palavra not in pontuacoes]\n",
        "  lista = ' '.join([str(elemento) for elemento in lista if not elemento.isdigit()])\n",
        "\n",
        "  return lista\n",
        "\n",
        "#cria uma nova coluna no dataframe 'sentence' com cada sentence tokenizado\n",
        "df['message_tratado'] = df['message'].apply(tratamento_texto).apply(preprocessamento)\n",
        "df['response_tratado'] = df['response'].apply(tratamento_texto).apply(preprocessamento)\n",
        "#Exibe o resultado\n",
        "df[df.columns[::-1]].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response_vetorizado_TFIDF</th>\n",
              "      <th>message_vetorizado_TFIDF</th>\n",
              "      <th>response_NER</th>\n",
              "      <th>message_NER</th>\n",
              "      <th>response_lematizado</th>\n",
              "      <th>message_lematizado</th>\n",
              "      <th>response_raiz</th>\n",
              "      <th>message_raiz</th>\n",
              "      <th>response_postagging</th>\n",
              "      <th>message_postagging</th>\n",
              "      <th>response_sem_stopwords</th>\n",
              "      <th>message_sem_stopwords</th>\n",
              "      <th>response_tokenizado</th>\n",
              "      <th>message_tokenizado</th>\n",
              "      <th>response_em_sentencas</th>\n",
              "      <th>message_em_sentencas</th>\n",
              "      <th>response_tratado</th>\n",
              "      <th>message_tratado</th>\n",
              "      <th>entailment_label</th>\n",
              "      <th>response</th>\n",
              "      <th>message</th>\n",
              "      <th>pair_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'l': 0.0, 'o': 0.27465307216702745, 'v': 0.27...</td>\n",
              "      <td>{'h': 0.13089867598202215, 'e': 0.130898675982...</td>\n",
              "      <td>[love, trailer, alreadi]</td>\n",
              "      <td>[heard, upcom, black, panther, movi]</td>\n",
              "      <td>[love, trailer, alreadi]</td>\n",
              "      <td>[heard, upcom, black, panther, movi]</td>\n",
              "      <td>[love, trailer, alreadi]</td>\n",
              "      <td>[heard, upcom, black, panther, movi]</td>\n",
              "      <td>[[(l, NN), (o, MD), (v, VB), (e, NN)], [(t, NN...</td>\n",
              "      <td>[[(h, NN), (e, VBZ), (a, DT), (r, NN), (d, NN)...</td>\n",
              "      <td>[love, trailer, already]</td>\n",
              "      <td>[heard, upcoming, black, panther, movie]</td>\n",
              "      <td>[i, have, and, i, am, so, in, love, with, the,...</td>\n",
              "      <td>[have, you, heard, of, the, upcoming, black, p...</td>\n",
              "      <td>[i have and i am so in love with the trailer a...</td>\n",
              "      <td>[have you heard of the upcoming black panther ...</td>\n",
              "      <td>b'i love trailer already!\\r\\n</td>\n",
              "      <td>b'have -PRON- hear upcoming black panther movi...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'i have and i am so in love with the trailer ...</td>\n",
              "      <td>b'have you heard of the upcoming black panther...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'c': 0.13862943611198905, 'h': 0.156944612666...</td>\n",
              "      <td>{'l': 0.27465307216702745, 'o': 0.549306144334...</td>\n",
              "      <td>[chadwick, realli, good, actor, black, panther]</td>\n",
              "      <td>[look, remark, far]</td>\n",
              "      <td>[chadwick, realli, good, actor, black, panther]</td>\n",
              "      <td>[look, remark, far]</td>\n",
              "      <td>[chadwick, realli, good, actor, black, panther]</td>\n",
              "      <td>[look, remark, far]</td>\n",
              "      <td>[[(c, NNS), (h, VBP), (a, DT), (d, NN), (w, NN...</td>\n",
              "      <td>[[(l, NN), (o, MD), (o, VB), (k, NN), (s, NN)]...</td>\n",
              "      <td>[chadwick, really, good, actor, black, panther]</td>\n",
              "      <td>[looks, remarkable, far]</td>\n",
              "      <td>[chadwick, really, is, a, good, actor, for, bl...</td>\n",
              "      <td>[it, looks, remarkable, so, far]</td>\n",
              "      <td>[chadwick really is a good actor for black pan...</td>\n",
              "      <td>[it looks remarkable so far]</td>\n",
              "      <td>b'chadwick good actor black panther.\\r\\n</td>\n",
              "      <td>b'it look remarkable far!\\r\\n</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'chadwick really is a good actor for black pa...</td>\n",
              "      <td>b'it looks remarkable so far!\\r\\n'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'t': 0.11552453009332421, 'r': 0.396084103177...</td>\n",
              "      <td>{'a': 0.04109743892168297, 'g': 0.346573590279...</td>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agre, realli, suitabl, role]</td>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agre, realli, suitabl, role]</td>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agre, realli, suitabl, role]</td>\n",
              "      <td>[[(t, NN), (r, VBZ), (a, DT), (i, JJ), (l, NN)...</td>\n",
              "      <td>[[(a, DT), (g, NN), (r, NN), (e, NN), (e, NN)]...</td>\n",
              "      <td>[trailer, kind, sad, though]</td>\n",
              "      <td>[agree, really, suitable, role]</td>\n",
              "      <td>[the, trailer, was, kind, of, sad, though]</td>\n",
              "      <td>[i, agree, he, really, is, suitable, for, the,...</td>\n",
              "      <td>[the trailer was kind of sad though]</td>\n",
              "      <td>[i agree   he really is suitable for the role]</td>\n",
              "      <td>b'the trailer kind sad though.\\r\\n</td>\n",
              "      <td>b'i agree -PRON- suitable role\\r\\n</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'the trailer was kind of sad though.\\r\\n'</td>\n",
              "      <td>b'i agree!. he really is suitable for the role...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'y': 0.9729550745276566, 'e': 0.0, 'h': 0.313...</td>\n",
              "      <td>{'b': 0.1831020481113516, 'o': 0.1831020481113...</td>\n",
              "      <td>[ye, hope, becom, one, best, super, hero]</td>\n",
              "      <td>[bother, father, die]</td>\n",
              "      <td>[ye, hope, becom, one, best, super, hero]</td>\n",
              "      <td>[bother, father, die]</td>\n",
              "      <td>[ye, hope, becom, one, best, super, hero]</td>\n",
              "      <td>[bother, father, die]</td>\n",
              "      <td>[[(y, NN), (e, NN), (s, NN)], [(h, NN), (o, MD...</td>\n",
              "      <td>[[(b, NN), (o, NN), (t, NN), (h, NN), (e, NN),...</td>\n",
              "      <td>[yes, hope, become, one, best, super, heroes]</td>\n",
              "      <td>[bother, father, died]</td>\n",
              "      <td>[yes, it, did, but, i, hope, he, become, one, ...</td>\n",
              "      <td>[how, so, did, it, bother, you, when, his, fat...</td>\n",
              "      <td>[yes  it did  but i hope he become one of the ...</td>\n",
              "      <td>[how so  did it bother you when his father died]</td>\n",
              "      <td>b'yes -PRON- hope -PRON- good super heroes!\\r\\n</td>\n",
              "      <td>b'how -PRON- bother -PRON- -PRON- father died?...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'yes, it did, but i hope he become one of the...</td>\n",
              "      <td>b'how so? did it bother you when his father di...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'m': 0.5198603854199589, 'o': 0.1732867951399...</td>\n",
              "      <td>{'s': 0.0, 'e': 0.0, 'c': 0.11552453009332421,...</td>\n",
              "      <td>[movi, releas, let, hope, good, trailer, show, u]</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[movi, releas, let, hope, good, trailer, show, u]</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[movi, releas, let, hope, good, trailer, show, u]</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[[(m, NN), (o, IN), (v, NN), (i, NN), (e, VBP)...</td>\n",
              "      <td>[[(s, NN), (e, NN), (c, VBP), (o, JJ), (n, JJ)...</td>\n",
              "      <td>[movie, released, lets, hope, good, trailer, s...</td>\n",
              "      <td>[second, statement]</td>\n",
              "      <td>[but, the, movie, will, be, a, while, until, i...</td>\n",
              "      <td>[i, second, that, statement]</td>\n",
              "      <td>[but the movie will be a while until it is rel...</td>\n",
              "      <td>[i second that statement]</td>\n",
              "      <td>b'but movie -PRON- release let hope -PRON- goo...</td>\n",
              "      <td>b'i second statement!\\r\\n</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>b'but the movie will be a while until it is re...</td>\n",
              "      <td>b'i second that statement!\\r\\n'</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           response_vetorizado_TFIDF  ... pair_ID\n",
              "0  {'l': 0.0, 'o': 0.27465307216702745, 'v': 0.27...  ...       0\n",
              "1  {'c': 0.13862943611198905, 'h': 0.156944612666...  ...       1\n",
              "2  {'t': 0.11552453009332421, 'r': 0.396084103177...  ...       2\n",
              "3  {'y': 0.9729550745276566, 'e': 0.0, 'h': 0.313...  ...       3\n",
              "4  {'m': 0.5198603854199589, 'o': 0.1732867951399...  ...       4\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbf0u0MvVaDt",
        "outputId": "93db19aa-a591-47cb-c9d7-efb16b6b68d3"
      },
      "source": [
        "#Visualização das informações do Dataset\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 320002 entries, 0 to 320001\n",
            "Data columns (total 22 columns):\n",
            " #   Column                     Non-Null Count   Dtype \n",
            "---  ------                     --------------   ----- \n",
            " 0   pair_ID                    320002 non-null  object\n",
            " 1   message                    320002 non-null  object\n",
            " 2   response                   320002 non-null  object\n",
            " 3   entailment_label           320002 non-null  object\n",
            " 4   message_tratado            320002 non-null  object\n",
            " 5   response_tratado           320002 non-null  object\n",
            " 6   message_em_sentencas       320002 non-null  object\n",
            " 7   response_em_sentencas      320002 non-null  object\n",
            " 8   message_tokenizado         320002 non-null  object\n",
            " 9   response_tokenizado        320002 non-null  object\n",
            " 10  message_sem_stopwords      320002 non-null  object\n",
            " 11  response_sem_stopwords     320002 non-null  object\n",
            " 12  message_postagging         320002 non-null  object\n",
            " 13  response_postagging        320002 non-null  object\n",
            " 14  message_raiz               320002 non-null  object\n",
            " 15  response_raiz              320002 non-null  object\n",
            " 16  message_lematizado         320002 non-null  object\n",
            " 17  response_lematizado        320002 non-null  object\n",
            " 18  message_NER                320002 non-null  object\n",
            " 19  response_NER               320002 non-null  object\n",
            " 20  message_vetorizado_TFIDF   320002 non-null  object\n",
            " 21  response_vetorizado_TFIDF  320002 non-null  object\n",
            "dtypes: object(22)\n",
            "memory usage: 53.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQqQOWgWvKc-",
        "outputId": "2a5a1961-00cb-482a-bad9-627c45e2a2b5"
      },
      "source": [
        "\n",
        "sns.countplot(df['entailment_label'], label = 'Inferência das Setenças');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEHCAYAAABiAAtOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcf0lEQVR4nO3df7xVdZ3v8dc7CNMMQTnjGD/u4SY1g9oPPSkz3pmpKERvN6jRhIddsXjI7abV9Jh+aHPn0jV5VLe6pGU2FAj48CE5ZMHM0EUG7ddNlGOSCOZ4whIYFRL8Uf4K/Nw/1ufocrvPYZ/DOnvHOe/n47Efe63P97vW+m4eG96sH3stRQRmZmZVelmrB2BmZoOPw8XMzCrncDEzs8o5XMzMrHIOFzMzq9zwVg/gD8WYMWOivb291cMwMzuk3HHHHb+JiLbausMltbe309nZ2ephmJkdUiT9ul7dh8XMzKxyDhczM6ucw8XMzCrncDEzs8o5XMzMrHIOFzMzq9yAhYukJZJ2Sbq7pv5hSb+QtEXS/y7VL5XUJeleSWeU6tOz1iXpklJ9oqTbsv5tSSOyfljOd2V7+0B9RjMzq28g91yWAtPLBUlvBWYAb4iIE4AvZX0yMAs4IZf5uqRhkoYBVwFnApOB2dkX4AvAwog4HtgLzM36XGBv1hdmPzMza6IBC5eI+BGwp6b834HPR8Qz2WdX1mcAKyLimYi4H+gCTs1XV0Rsi4hngRXADEkC3gaszOWXATNL61qW0yuBqdnfzMyapNm/0H8t8BeSFgBPAx+PiI3AWGBDqd+OrAFsr6mfBhwDPBoR++r0H9u9TETsk/RY9v9N7WAkzQPmAUyYMOGgP9wpn1h+0OuwweeOL57f6iHwwGUntXoI9gdowv/cPGDrbvYJ/eHA0cAU4BPADa3cq4iIRRHREREdbW0vuTWOmZn1U7PDZQdwYxRuB54DxgA7gfGlfuOy1lP9EWCUpOE1dcrLZPtR2d/MzJqk2eHyPeCtAJJeC4ygOFy1GpiVV3pNBCYBtwMbgUl5ZdgIipP+qyMigFuAs3O9c4BVOb0658n2m7O/mZk1yYCdc5F0PfAWYIykHcB8YAmwJC9PfhaYk//wb5F0A7AV2AdcFBH7cz0XA2uBYcCSiNiSm/gUsELS5cCdwOKsLwauldRFcUHBrIH6jGZmVt+AhUtEzO6h6X099F8ALKhTXwOsqVPfRnE1WW39aeCcPg3WzMwq5V/om5lZ5RwuZmZWOYeLmZlVzuFiZmaVc7iYmVnlHC5mZlY5h4uZmVXO4WJmZpVzuJiZWeUcLmZmVjmHi5mZVc7hYmZmlXO4mJlZ5RwuZmZWOYeLmZlVzuFiZmaVG7BwkbRE0q586mRt299KCkljcl6SrpTUJekuSSeX+s6RdF++5pTqp0janMtcKUlZP1rSuuy/TtLogfqMZmZW30DuuSwFptcWJY0HpgEPlMpnApPyNQ+4OvseTfF45NMonjo5vxQWVwMXlpbr3tYlwPqImASsz3kzM2uiAQuXiPgRxTPsay0EPglEqTYDWB6FDcAoSccBZwDrImJPROwF1gHTs21kRGyIiACWAzNL61qW08tKdTMza5KmnnORNAPYGRE/r2kaC2wvze/IWm/1HXXqAMdGxIM5/RBwbDWjNzOzRg1v1oYkHQF8muKQWFNEREiKntolzaM4DMeECROaNSwzs0GvmXsurwEmAj+X9CtgHPAzSX8M7ATGl/qOy1pv9XF16gAP52Ez8n1XTwOKiEUR0RERHW1tbQfx0czMrKxp4RIRmyPijyKiPSLaKQ5lnRwRDwGrgfPzqrEpwGN5aGstME3S6DyRPw1Ym22PS5qSV4mdD6zKTa0Guq8qm1Oqm5lZkwzkpcjXA7cCr5O0Q9LcXrqvAbYBXcA3gQ8BRMQe4LPAxnxdljWyz7dymV8C38/654F3SLoPeHvOm5lZEw3YOZeImH2A9vbSdAAX9dBvCbCkTr0TOLFO/RFgah+Ha2ZmFfIv9M3MrHIOFzMzq5zDxczMKudwMTOzyjlczMyscg4XMzOrnMPFzMwq53AxM7PKOVzMzKxyDhczM6ucw8XMzCrncDEzs8o5XMzMrHIOFzMzq5zDxczMKudwMTOzyjlczMyscgP5mOMlknZJurtU+6KkX0i6S9J3JY0qtV0qqUvSvZLOKNWnZ61L0iWl+kRJt2X925JGZP2wnO/K9vaB+oxmZlbfQO65LAWm19TWASdGxOuBfwMuBZA0GZgFnJDLfF3SMEnDgKuAM4HJwOzsC/AFYGFEHA/sBeZmfS6wN+sLs5+ZmTXRgIVLRPwI2FNTuyki9uXsBmBcTs8AVkTEMxFxP9AFnJqvrojYFhHPAiuAGZIEvA1YmcsvA2aW1rUsp1cCU7O/mZk1SSvPuXwA+H5OjwW2l9p2ZK2n+jHAo6Wg6q6/aF3Z/lj2NzOzJmlJuEj6O2AfcF0rtl8axzxJnZI6d+/e3cqhmJkNKk0PF0kXAO8EzouIyPJOYHyp27is9VR/BBglaXhN/UXryvajsv9LRMSiiOiIiI62traD/GRmZtatqeEiaTrwSeBdEfFkqWk1MCuv9JoITAJuBzYCk/LKsBEUJ/1XZyjdApydy88BVpXWNSenzwZuLoWYmZk1wfADd+kfSdcDbwHGSNoBzKe4OuwwYF2eY98QER+MiC2SbgC2Uhwuuygi9ud6LgbWAsOAJRGxJTfxKWCFpMuBO4HFWV8MXCupi+KCglkD9RnNzKy+AQuXiJhdp7y4Tq27/wJgQZ36GmBNnfo2iqvJautPA+f0abBmZlYp/0LfzMwq53AxM7PKOVzMzKxyDhczM6ucw8XMzCrncDEzs8o5XMzMrHIOFzMzq5zDxczMKudwMTOzyjlczMyscg4XMzOrnMPFzMwq53AxM7PKOVzMzKxyDhczM6ucw8XMzCo3YOEiaYmkXZLuLtWOlrRO0n35PjrrknSlpC5Jd0k6ubTMnOx/n6Q5pfopkjbnMlcqn5vc0zbMzKx5BnLPZSkwvaZ2CbA+IiYB63Me4ExgUr7mAVdDERTAfOA0ikcazy+FxdXAhaXlph9gG2Zm1iQDFi4R8SNgT015BrAsp5cBM0v15VHYAIySdBxwBrAuIvZExF5gHTA920ZGxIaICGB5zbrqbcPMzJqk2edcjo2IB3P6IeDYnB4LbC/125G13uo76tR728ZLSJonqVNS5+7du/vxcczMrJ6WndDPPY5o5TYiYlFEdERER1tb20AOxcxsSGl2uDych7TI911Z3wmML/Ubl7Xe6uPq1HvbhpmZNUmzw2U10H3F1xxgVal+fl41NgV4LA9trQWmSRqdJ/KnAWuz7XFJU/IqsfNr1lVvG2Zm1iTDB2rFkq4H3gKMkbSD4qqvzwM3SJoL/Bp4b3ZfA5wFdAFPAu8HiIg9kj4LbMx+l0VE90UCH6K4Iu1w4Pv5opdtmJlZkwxYuETE7B6aptbpG8BFPaxnCbCkTr0TOLFO/ZF62zAzs+bxL/TNzKxyDhczM6ucw8XMzCrncDEzs8o1FC6S1jdSMzMzgwNcLSbpFcARFJcTjwaUTSN54XYrZmZmL3KgS5H/G/A3wKuBO3ghXB4HvjaA4zIzs0NYr+ESEVcAV0j6cER8tUljMjOzQ1xDP6KMiK9K+nOgvbxMRCwfoHGZmdkhrKFwkXQt8BpgE7A/y93PUTEzM3uRRm//0gFMztu0mJmZ9arR37ncDfzxQA7EzMwGj0b3XMYAWyXdDjzTXYyIdw3IqMzM7JDWaLh8ZiAHYWZmg0ujV4v9cKAHYmZmg0ejV4s9wQvPoh8BvBz4XUSMHKiBmZnZoavRPZdXdU/nY4VnAFMGalBmZnZo6/NdkaPwPeCM/m5U0sckbZF0t6TrJb1C0kRJt0nqkvRtSSOy72E535Xt7aX1XJr1eyWdUapPz1qXpEv6O04zM+ufRg+Lvac0+zKK37083Z8NShoLfITidzNPSboBmAWcBSyMiBWSvgHMBa7O970RcbykWcAXgHMlTc7lTqC499m/SnptbuYq4B3ADmCjpNURsbU/4zUzs75rdM/lv5ReZwBPUBwa66/hwOGShlPcdflB4G3AymxfBszM6Rk5T7ZPLR2aWxERz0TE/UAXcGq+uiJiW0Q8C6w4yLGamVkfNXrO5f1VbTAidkr6EvAA8BRwE8Udlx+NiH3ZbQcv3NJ/LLA9l90n6THgmKxvKK26vMz2mvpp9cYiaR4wD2DChAkH98HMzOx5jT4sbJyk70rala/vSBrXnw3mc2FmABMpDme9Epjen3UdrIhYFBEdEdHR1tbWiiGYmQ1KjR4WuwZYTREGrwb+KWv98Xbg/ojYHRG/B24ETgdG5WEygHHAzpzeCYwHyPajgEfK9ZpleqqbmVmTNBoubRFxTUTsy9dSoL//1X8AmCLpiDx3MhXYCtwCnJ195gCrcnp1zpPtN+cNNFcDs/JqsonAJOB2YCMwKa8+G0Fx0n91P8dqZmb90OjtXx6R9D7g+pyfTbH30GcRcZuklcDPgH3AncAi4F+AFZIuz9riXGQxcK2kLmAPRVgQEVvySrOtuZ6LImI/gKSLgbXAMGBJRGzpz1jNzKx/Gg2XDwBfBRZS/FL/p8AF/d1oRMwH5teUt1Fc6VXb92ngnB7WswBYUKe+BljT3/GZmdnBaTRcLgPmRMReAElHA1+iCB0zM7MXafScy+u7gwUgIvYAbxqYIZmZ2aGu0XB5WV5CDDy/59LoXo+ZmQ0xjQbEl4FbJf1jzp9DnXMdZmZm0Pgv9JdL6qS4RQvAe3yvLjMz60nDh7YyTBwoZmZ2QH2+5b6ZmdmBOFzMzKxyDhczM6ucw8XMzCrncDEzs8o5XMzMrHIOFzMzq5zDxczMKudwMTOzyjlczMyscg4XMzOrXEvCRdIoSSsl/ULSPZL+TNLRktZJui/fR2dfSbpSUpekuySdXFrPnOx/n6Q5pfopkjbnMldKUis+p5nZUNWqPZcrgP8bEX8CvAG4B7gEWB8Rk4D1OQ9wJjApX/OAq+H5Z8rMB06jeDzy/NIzZ64GLiwtN70Jn8nMzFLTw0XSUcBfAosBIuLZiHgUmAEsy27LgJk5PQNYHoUNwChJxwFnAOsiYk8+JXMdMD3bRkbEhogIYHlpXWZm1gSt2HOZCOwGrpF0p6RvSXolcGxEPJh9HgKOzemxwPbS8juy1lt9R536S0iaJ6lTUufu3bsP8mOZmVm3VoTLcOBk4OqIeBPwO144BAZA7nHEQA8kIhZFREdEdLS1tQ305szMhoxWhMsOYEdE3JbzKynC5uE8pEW+78r2ncD40vLjstZbfVydupmZNUnTwyUiHgK2S3pdlqZSPOFyNdB9xdccYFVOrwbOz6vGpgCP5eGztcA0SaPzRP40YG22PS5pSl4ldn5pXWZm1gQNP+a4Yh8GrpM0AtgGvJ8i6G6QNBf4NfDe7LsGOAvoAp7MvkTEHkmfBTZmv8siYk9OfwhYChwOfD9fZmbWJC0Jl4jYBHTUaZpap28AF/WwniXAkjr1TuDEgxymmZn1k3+hb2ZmlXO4mJlZ5RwuZmZWOYeLmZlVzuFiZmaVc7iYmVnlHC5mZlY5h4uZmVXO4WJmZpVzuJiZWeUcLmZmVjmHi5mZVc7hYmZmlXO4mJlZ5RwuZmZWOYeLmZlVzuFiZmaVa1m4SBom6U5J/5zzEyXdJqlL0rfzEchIOiznu7K9vbSOS7N+r6QzSvXpWeuSdEmzP5uZ2VDXyj2XjwL3lOa/ACyMiOOBvcDcrM8F9mZ9YfZD0mRgFnACMB34egbWMOAq4ExgMjA7+5qZWZO0JFwkjQP+M/CtnBfwNmBldlkGzMzpGTlPtk/N/jOAFRHxTETcD3QBp+arKyK2RcSzwIrsa2ZmTdKqPZevAJ8Ensv5Y4BHI2Jfzu8Axub0WGA7QLY/lv2fr9cs01P9JSTNk9QpqXP37t0H+5nMzCw1PVwkvRPYFRF3NHvbtSJiUUR0RERHW1tbq4djZjZoDG/BNk8H3iXpLOAVwEjgCmCUpOG5dzIO2Jn9dwLjgR2ShgNHAY+U6t3Ky/RUNzOzJmj6nktEXBoR4yKineKE/M0RcR5wC3B2dpsDrMrp1TlPtt8cEZH1WXk12URgEnA7sBGYlFefjchtrG7CRzMzs9SKPZeefApYIely4E5gcdYXA9dK6gL2UIQFEbFF0g3AVmAfcFFE7AeQdDGwFhgGLImILU39JGZmQ1xLwyUifgD8IKe3UVzpVdvnaeCcHpZfACyoU18DrKlwqGZm1gf+hb6ZmVXO4WJmZpVzuJiZWeUcLmZmVjmHi5mZVc7hYmZmlXO4mJlZ5RwuZmZWOYeLmZlVzuFiZmaVc7iYmVnlHC5mZlY5h4uZmVXO4WJmZpVzuJiZWeUcLmZmVjmHi5mZVa7p4SJpvKRbJG2VtEXSR7N+tKR1ku7L99FZl6QrJXVJukvSyaV1zcn+90maU6qfImlzLnOlJDX7c5qZDWWt2HPZB/xtREwGpgAXSZoMXAKsj4hJwPqcBzgTmJSvecDVUIQRMB84jeLxyPO7Ayn7XFhabnoTPpeZmaWmh0tEPBgRP8vpJ4B7gLHADGBZdlsGzMzpGcDyKGwARkk6DjgDWBcReyJiL7AOmJ5tIyNiQ0QEsLy0LjMza4KWnnOR1A68CbgNODYiHsymh4Bjc3ossL202I6s9VbfUadeb/vzJHVK6ty9e/dBfRYzM3tBy8JF0pHAd4C/iYjHy225xxEDPYaIWBQRHRHR0dbWNtCbMzMbMloSLpJeThEs10XEjVl+OA9pke+7sr4TGF9afFzWequPq1M3M7MmacXVYgIWA/dExP8pNa0Guq/4mgOsKtXPz6vGpgCP5eGztcA0SaPzRP40YG22PS5pSm7r/NK6zMysCYa3YJunA/8V2CxpU9Y+DXweuEHSXODXwHuzbQ1wFtAFPAm8HyAi9kj6LLAx+10WEXty+kPAUuBw4Pv5MjOzJml6uETET4CefncytU7/AC7qYV1LgCV16p3AiQcxTDMzOwj+hb6ZmVXO4WJmZpVzuJiZWeUcLmZmVjmHi5mZVc7hYmZmlXO4mJlZ5RwuZmZWOYeLmZlVzuFiZmaVc7iYmVnlHC5mZlY5h4uZmVXO4WJmZpVzuJiZWeUcLmZmVjmHi5mZVW7Qhouk6ZLuldQl6ZJWj8fMbCgZlOEiaRhwFXAmMBmYLWlya0dlZjZ0DMpwAU4FuiJiW0Q8C6wAZrR4TGZmQ8bwVg9ggIwFtpfmdwCn1XaSNA+Yl7O/lXRvE8Y2VIwBftPqQfwh0JfmtHoI9mL+bnabryrW8h/qFQdruDQkIhYBi1o9jsFIUmdEdLR6HGa1/N1sjsF6WGwnML40Py5rZmbWBIM1XDYCkyRNlDQCmAWsbvGYzMyGjEF5WCwi9km6GFgLDAOWRMSWFg9rqPHhRvtD5e9mEygiWj0GMzMbZAbrYTEzM2shh4uZmVXO4TLESdovaZOkuyX9o6Qjsj5O0ipJ90n6paQr8uIIJB0h6TpJm3O5n0g6Mtt+K+mkXOcmSXsk3Z/T/yqpPZc5QtIjkkbWjOd7ks6VdIGk3aX1bPJdFoYGSSHpy6X5j0v6TE5/RtLOmu/FqGw7VdIP8jv7M0n/IumkmnVvkrQip99fWsez+X3eJOnz+f37mqS/knRrzTqGS3pY0qslLS19vzdJ+umA/wEdIhwu9lREvDEiTgSeBT4oScCNwPciYhLwWuBIYEEu81Hg4Yg4KZebC/y+e4URsTnX+UaKq/Q+kfNvL/V5kuKCi3d31yQdBfwn4J+y9O3u9eRr68D8EdgfmGeA90ga00P7wprvxaOSjgVuAD4dEZMi4mTgc8BruheS9KcUF/j8haRXRsQ1pe/pvwNvzfnyvQh/DIyTVP6h4NuBLRHx7zn/idJY/rySP4FBwOFiZT8GjgfeBjwdEdcARMR+4GPAB3LP5jhKvxuKiHsj4pl+bO96isvEu70bWJvBY0PXPooruj7Wh2UuBpZFxPN7DhHxk4j4XqnPbOBa4CYavB1URDxHEVrl7+ksiu+u9cLhYkCxq09xo8/NwAnAHeX2iHgceIAifJYAn5J0q6TLJU3q52bXAidLOibna//Snltz+OPwfm7HDj1XAefl3mytj5W+E7dk7QTgZwdY57kU9xm8niJoGvX8f4IkHQacBXyn1P7F0niu68N6BzWHix0uaRPQSREeiw+0QERsAv4j8EXgaGBjHnLok7yp6Grg7DwE8iaKwOlWe1jsqb5uww5N+Z+Z5cBH6jSXD4u9td7ykm6TdI+kK3K+A/hNRDwArAfeJOnoBsfSCRwp6XUU/wG7LSL2lLqUD4ud1/inHNwG5Y8orU+eymPOz5O0FTi7pjYSmAB0AUTEbynOy9wo6TmK/83d04/tXw/8PSBgVUT8/gD9bej4CsXeyDUN9N0CnAysAoiI0ySdDbwz22cDfyLpVzk/Evhr4JsNjqV77+VP8SGxhnjPxepZDxwh6Xx4/vk4XwaWRsSTkk6XNDrbRlA8M+fX/dzWD4BJwEX4L62V5N7BDRQXjBzIVcAFkson1LuvfHwZ8F7gpIhoj4h2inMufT009j6K85Gr+rDckOVwsZeI4rYN7wbOkXQf8G/A08Cns8trgB9K2gzcSXFI7Tv11tXAtp4DVgLHAD+saa495+IrcYaeL1PcIr/sYzXfi/aIeIjinMrnVDx99qcUe99fA/4C2Fm6ugvgR8BkScc1MoiIuAf4HXBzRPyupvmLNeMZ0Y/POej49i9mZlY577mYmVnlHC5mZlY5h4uZmVXO4WJmZpVzuJiZWeUcLmZmVjmHi1kfSJrZyK3/JX2w9CPUpflr8YEc1wWSXn2APj/I26D01udXvdyNuKftfq3R/jZ0OFzM+mYmxR0JehUR34iI5U0YT7cLgF7DxayZHC425El6n6Tb89fV/yBpmIqHni2Q9HNJGyQdm3cIeBcv/CL7NZIulLQx+31HLzxs7TOSPl5nW7+S9LlcvlPSyZLWqngg2wdL/T6R671L0v/KWnvejPGbkrZIuknS4blX1AFc1+jdoyVdndvf0r3+kk+qeHDW7ZKOz/5t+fk25uv0fv+B25DgcLEhLe/mfC5wet7Acz9wHvBKYENEvIHiViEX5rNCyg8/+yVwY0S8OfvdQ2P3wXogt/VjYCnFbUqmAN0hMo3ifmunAm8ETpH0l7nsJOCqiDgBeBT464hYSXELnvP6cPfov4uIDuD1wF9Jen2p7bGIOIni1ilfydoVFHcjfjPFDR+/1cA2bAjzXZFtqJsKnELx2ACAw4FdFE/l/Ofscwfwjh6WP1HS5cAoiqd1ru2hX9nqfN8MHBkRTwBPSHpGxSN7p+Xrzux3JEWoPADcn4886B5XewPbq+e9kuZR/BtwHMWhvruy7frS+8KcfjvFvbi6lx+pfLS1WT0OFxvqRPEEw0tfVJQ+Hi/ceG8/Pf9dWQrMjIifS7oAeEsD2+x+audzpenu+eE5ps9FxD/UjKm9pv9+ijDsE0kTgY8Db46IvZKWAq8odYk60y8DpkTE0zXr6uvmbYjwYTEb6tZTPKzsjwAkHa0XPy+91hPAq0rzrwIelPRyisNpVVhL8UjpI3NMY7vH14dx9WYkxR1+H1Px7Pkza9rPLb3fmtM3AR/u7iDpjZj1wnsuNqRFxFZJ/wO4KZ/78XuKZ8v0ZAXwTUkfoThX8vfAbcDufG/0H/jexnRTngu6NfcMfkvxLJH9vSy2FPiGpKeAP+vtvEvuZd0J/ALYDvy/mi6jJd1FsZfU/cyTjwBXZX04xXmoD2LWA99y38zMKufDYmZmVjkfFjMbZCR9F5hYU/5URDRyJZtZJXxYzMzMKufDYmZmVjmHi5mZVc7hYmZmlXO4mJlZ5f4/CywYQqkbDKAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyBa8IatCrui"
      },
      "source": [
        "\n",
        "dias = int(df.shape[0] * 0.2) # 20% do Dataset\n",
        "train_df = df.iloc[:-dias,0:15].copy()\n",
        "val_df = df.iloc[-dias:,0:15].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWz0vMizvPGO",
        "outputId": "74a581b1-b847-4c1f-877b-b81cd1cb9952"
      },
      "source": [
        "plt.figure(figsize=(18,5))\n",
        "plt.title('Total Inferência das Setenças')\n",
        "plt.plot(train_df['entailment_label']=='POSITIVE', color='b')\n",
        "plt.plot(val_df['entailment_label']=='POSITIVE', color='orange')\n",
        "plt.legend(['Treino','Teste'])\n",
        "# plt.yticks(np.arange(0, 1000, step=50))\n",
        "plt.xlabel('Quantidade')\n",
        "plt.ylabel('Inferencia')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "S4MPh-GJvR9p",
        "outputId": "9e20ff91-806a-45fb-805d-1cc8a1cceb80"
      },
      "source": [
        "plt.figure(figsize=(18,5))\n",
        "plt.title('Total Inferência das Setenças')\n",
        "plt.plot(train_df['entailment_label']=='NEGATIVE', color='b')\n",
        "plt.plot(val_df['entailment_label']=='NEGATIVE', color='orange')\n",
        "plt.legend(['Treino','Teste'])\n",
        "# plt.yticks(np.arange(0, 1000, step=50))\n",
        "plt.xlabel('Quantidade')\n",
        "plt.ylabel('Inferencia')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-EvNNXgKxl-"
      },
      "source": [
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import pickle\n",
        "import os\n",
        "import transformers\n",
        "from transformers import BertTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9Mz0dUCL6u7",
        "outputId": "3c06f405-1257-4f1e-b05f-9cb1c882293c"
      },
      "source": [
        "# Requires the latest pip\n",
        "!pip install --upgrade pip\n",
        "\n",
        "# Current stable release for CPU and GPU\n",
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 8.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.3.1\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (4.8.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYDF4B4FGtEn"
      },
      "source": [
        "#### Model Fitted e Resultados do processo de treinamento (28/06/2021)\n",
        "\n",
        "#### Execução com Held-Out-Data (Dados não vistos) (12/07/2021)\n",
        "\n",
        "#### BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRHG7poRYjSb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180,
          "referenced_widgets": [
            "3c9d439dfc5a40f89745512a4e3596d2",
            "2d0f35306f4548e798030f199ba8f841",
            "fee3392254e447beb9576d5bf49a2436",
            "70e61c5c4b0048e2844f9621dfbe42a2",
            "df83d284277543f88177be135447ab34",
            "08518fb84956453ea85bdf2a99c7bdd4",
            "0bddaf77964f4ff1a47bce32a6572c17",
            "be403b74d1224939bd122170e8218e9a",
            "0e31f463a2234150b24eaa176b6c032b",
            "bda1211407214be0a04f20b6a42acac6",
            "95f7e78672ce45d79fe8970f3c770759",
            "84ab7d5a03324694914d4cfc8b3701db",
            "d5fa7eda8dd14c79bd078f92fa4f8000",
            "5fd249c4050640b1b711c6d89085a446",
            "82be925a745f4f2baa8fbe9daac136c4",
            "a741fd8ab21646a1ad2fd6a5dacc838f",
            "69b730509a7e407f8f2b8f4dac84335e",
            "6cf9520f9f444ed8bbea0c22eb4256d4",
            "9c7a7eb5340e4665bccd2f5344181f53",
            "166efb7f0b2c46b9951cafe91ae83863",
            "9cb612c45e42473092cc36d713f12e91",
            "4225fcbd224a499aba986280b6c43fb9",
            "3ade45b8399a4c528d82bb3748f1a082",
            "a69f1a63ca6247c2971c4c14e0df6463",
            "170937f75ddb4672acd9b6c3aaabde83",
            "31556aabcb744c7ca2ce1de023d459a1",
            "c5b17df296584663aa3db89504f7df74",
            "f57da676e1774a688cfe66f27f6f3d79",
            "9642e92e145645dc8f1a53870b361323",
            "24be63a16a6e46358cb325c363d5cd48",
            "55a8972fed1c4e7bac7c0570d668ced5",
            "a0e482e9168c4e83a8680c67dddf2ccc",
            "574da8901d87410b8afd95e530721098",
            "c01ec1eaee7b4f7b82f57af00d7757f4",
            "f6139022f46741a59fb8efcf68fdfa3f",
            "0032a1ae05fc48cabe434047a55798b1",
            "3bc5c86650b84f16b0610bd874b2e92e",
            "f7ae70302d96465cbac0fb232f5c2739",
            "e7b4ab5fc5c44f7fbc7c18c275f8b537",
            "ddf6ab9da7e542e7ae9aa90380451897",
            "70c22dfca1744250854b2549a340805b",
            "a106f7c51bb445d6936710ee859276f8",
            "701c5c8de12943a7ae2ef0f503b4426d",
            "ed7a9cb9eabc4eda9be8530e134648ce"
          ]
        },
        "outputId": "80807761-95b1-4c93-d80c-a16a43bc2732"
      },
      "source": [
        "class MNLIDataBert(Dataset):\n",
        "\n",
        "  def __init__(self, train_df, val_df):\n",
        "    self.label_dict = {'POSITIVE': 0, 'NEGATIVE': 1}\n",
        "\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "\n",
        "    self.base_path = '/content/'\n",
        "    self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) # Using a pre-trained BERT tokenizer to encode sentences\n",
        "    self.train_data = None\n",
        "    self.val_data = None\n",
        "    self.init_data()\n",
        "\n",
        "  def init_data(self):\n",
        "    self.train_data = self.load_data(self.train_df)\n",
        "    self.val_data = self.load_data(self.val_df)\n",
        "\n",
        "  def load_data(self, df):\n",
        "    MAX_LEN = 512\n",
        "    token_ids = []\n",
        "    mask_ids = []\n",
        "    seg_ids = []\n",
        "    y = []\n",
        "\n",
        "    premise_list = df['message_tratado'].to_list()\n",
        "    hypothesis_list = df['response_tratado'].to_list()\n",
        "    label_list = df['entailment_label'].to_list()\n",
        "\n",
        "    for (premise, hypothesis, label) in zip(premise_list, hypothesis_list, label_list):\n",
        "      premise_id = self.tokenizer.encode(premise, add_special_tokens = False)\n",
        "      hypothesis_id = self.tokenizer.encode(hypothesis, add_special_tokens = False)\n",
        "      pair_token_ids = [self.tokenizer.cls_token_id] + premise_id + [self.tokenizer.sep_token_id] + hypothesis_id + [self.tokenizer.sep_token_id]\n",
        "      premise_len = len(premise_id)\n",
        "      hypothesis_len = len(hypothesis_id)\n",
        "\n",
        "      segment_ids = torch.tensor([0] * (premise_len + 2) + [1] * (hypothesis_len + 1))  # sentence 0 and sentence 1\n",
        "      attention_mask_ids = torch.tensor([1] * (premise_len + hypothesis_len + 3))  # mask padded values\n",
        "\n",
        "      token_ids.append(torch.tensor(pair_token_ids))\n",
        "      seg_ids.append(segment_ids)\n",
        "      mask_ids.append(attention_mask_ids)\n",
        "      y.append(self.label_dict[label])\n",
        "    \n",
        "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
        "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
        "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
        "    y = torch.tensor(y)\n",
        "    dataset = TensorDataset(token_ids, mask_ids, seg_ids, y)\n",
        "    print(len(dataset))\n",
        "    return dataset\n",
        "\n",
        "  def get_data_loaders(self, batch_size=32, shuffle=True):\n",
        "    train_loader = DataLoader(\n",
        "      self.train_data,\n",
        "      shuffle=shuffle,\n",
        "      batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "      self.val_data,\n",
        "      shuffle=shuffle,\n",
        "      batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "  \n",
        "mnli_dataset = MNLIDataBert(train_df, val_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c9d439dfc5a40f89745512a4e3596d2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84ab7d5a03324694914d4cfc8b3701db",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ade45b8399a4c528d82bb3748f1a082",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c01ec1eaee7b4f7b82f57af00d7757f4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256002\n",
            "64000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_8DLeZ98Ewu"
      },
      "source": [
        "train_loader, val_loader = mnli_dataset.get_data_loaders(batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko6MXsBa8K4Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b1aa1a61ecd540358d1d3564fdf60a6a",
            "cbd4b859e77b4ac5b6e4c9243fbf04ed",
            "6ac83391ad1840e0816adaf14dedafd3",
            "fa352c717e8342328520e0cca0823914",
            "c09f43e6e8584102b35bb06d11a87ebf",
            "ac1f3b3822234b6d985c144dcface8f9",
            "5f793c743e7f4df5b93e472646e89305",
            "004d9c79f722475b8364995ca6bd8b07",
            "9599a835324e4c82a0b8633fcf944673",
            "e5cddac230be4070933f8a41544bd795",
            "e9fbd0eea30342b9a2955ac70b42778f"
          ]
        },
        "outputId": "94bdc879-542d-491a-8ea2-8d4edcbf0817"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1aa1a61ecd540358d1d3564fdf60a6a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bffwM8iKYjVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce694ab-ce5d-45e0-c5ca-d0363eee86d4"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, correct_bias=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3Od9efw9C7g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eebae93-563a-48af-a17a-e59ab861ecf3"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 109,483,778 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlI4Wdgz9DDp"
      },
      "source": [
        "def multi_acc(y_pred, y_test):\n",
        "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
        "  return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTCYlpw2YjYL"
      },
      "source": [
        "def multi_acc(y_pred, y_test):\n",
        "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
        "  return acc\n",
        "\n",
        "import time\n",
        "\n",
        "EPOCHS = 1\n",
        "\n",
        "def train(model, train_loader, val_loader, optimizer):  \n",
        "  total_step = len(train_loader)\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    total_train_acc  = 0\n",
        "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      pair_token_ids = pair_token_ids.to(device)\n",
        "      mask_ids = mask_ids.to(device)\n",
        "      seg_ids = seg_ids.to(device)\n",
        "      labels = y.to(device)\n",
        "\n",
        "      loss, prediction = model(pair_token_ids, \n",
        "                             token_type_ids=seg_ids, \n",
        "                             attention_mask=mask_ids, \n",
        "                             labels=labels).values()\n",
        "\n",
        "      acc = multi_acc(prediction, labels)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      total_train_loss += loss.item()\n",
        "      total_train_acc  += acc.item()\n",
        "\n",
        "    train_acc  = total_train_acc/len(train_loader)\n",
        "    train_loss = total_train_loss/len(train_loader)\n",
        "    model.eval()\n",
        "    total_val_acc  = 0\n",
        "    total_val_loss = 0\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(val_loader):\n",
        "        optimizer.zero_grad()\n",
        "        pair_token_ids = pair_token_ids.to(device)\n",
        "        mask_ids = mask_ids.to(device)\n",
        "        seg_ids = seg_ids.to(device)\n",
        "        labels = y.to(device)\n",
        "        \n",
        "        loss, prediction = model(pair_token_ids, \n",
        "                             token_type_ids=seg_ids, \n",
        "                             attention_mask=mask_ids, \n",
        "                             labels=labels).values()\n",
        "        \n",
        "        acc = multi_acc(prediction, labels)\n",
        "\n",
        "        total_val_loss += loss.item()\n",
        "        total_val_acc  += acc.item()\n",
        "\n",
        "    val_acc  = total_val_acc/len(val_loader)\n",
        "    val_loss = total_val_loss/len(val_loader)\n",
        "    end = time.time()\n",
        "    hours, rem = divmod(end-start, 3600)\n",
        "    minutes, seconds = divmod(rem, 60)\n",
        "\n",
        "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
        "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh2G4_YDURf6",
        "outputId": "c4eb5b94-8e47-4642-e8ab-dc257ff0089f"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwkXdaZI9MoY"
      },
      "source": [
        "train(model, train_loader, val_loader, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9YkZ6QCTYEp"
      },
      "source": [
        "def plot_scores(history):\n",
        "    acc = [x['val_acc'] for x in history]\n",
        "    plt.plot(acc, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('acc')\n",
        "    plt.title('acc vs. No. of epochs');\n",
        "\n",
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaIyhxn7Thtc"
      },
      "source": [
        "plot_losses(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y12K-NEnz0HZ"
      },
      "source": [
        "def get_prediction(str):\n",
        " str = re.sub(r'[^a-zA-Z ]+', '', str)\n",
        " test_text = [str]\n",
        " model.eval()\n",
        " \n",
        " tokens_test_data = mnli_dataset.tokenizer(\n",
        " test_text,\n",
        " pad_to_max_length=True,\n",
        " truncation=True,\n",
        " return_token_type_ids=False\n",
        " )\n",
        " test_seq = torch.tensor(tokens_test_data['input_ids'])\n",
        " test_mask = torch.tensor(tokens_test_data['attention_mask'])\n",
        " \n",
        " preds = None\n",
        " with torch.no_grad():\n",
        "   preds = model(test_seq.to(device), test_mask.to(device))\n",
        "\n",
        " preds = np.argmax(preds)\n",
        " print(\"Intent Identified: \", le.inverse_transform(preds)[0])\n",
        " return le.inverse_transform(preds)[0]\n",
        "\n",
        "def get_response(message): \n",
        "  intent = get_prediction(message)\n",
        "  for i in data['intents']: \n",
        "    if i[\"tag\"] == intent:\n",
        "      result = random.choice(i[\"responses\"])\n",
        "      break\n",
        "  print(f\"Response : {result}\")\n",
        "  return \"Intent: \"+ intent + '\\n' + \"Response: \" + result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7AsaASCOBvi"
      },
      "source": [
        "get_response(\"why dont you introduce yourself\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNS_zIXRftBc"
      },
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}